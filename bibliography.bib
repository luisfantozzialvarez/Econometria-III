@article{blanchard1989dynamic,
	title={The Dynamic Effects of Aggregate Demand and Supply Disturbances},
	author={Blanchard, Olivier Jean and Quah, Danny},
	journal={The American Economic Review},
	volume={79},
	number={4},
	pages={655--673},
	year={1989}
}

@article{uhlig2005,
	title = {What are the effects of monetary policy on output? Results from an agnostic identification procedure},
	journal = {Journal of Monetary Economics},
	volume = {52},
	number = {2},
	pages = {381-419},
	year = {2005},
	issn = {0304-3932},
	doi = {https://doi.org/10.1016/j.jmoneco.2004.05.007},
	url = {https://www.sciencedirect.com/science/article/pii/S0304393205000073},
	author = {Harald Uhlig},
	keywords = {Vector autoregression, Monetary policy shocks, Identification, Monetary neutrality},
	abstract = {This paper proposes to estimate the effects of monetary policy shocks by a new agnostic method, imposing sign restrictions on the impulse responses of prices, nonborrowed reserves and the federal funds rate in response to a monetary policy shock. No restrictions are imposed on the response of real GDP to answer the key question in the title. I find that “contractionary” monetary policy shocks have no clear effect on real GDP, even though prices move only gradually in response to a monetary policy shock. Neutrality of monetary policy shocks is not inconsistent with the data.}
}

@article{antolin2018,
	Author = {Antolín-Díaz, Juan and Rubio-Ramírez, Juan F.},
	Title = {Narrative Sign Restrictions for SVARs},
	Journal = {American Economic Review},
	Volume = {108},
	Number = {10},
	Year = {2018},
	Month = {October},
	Pages = {2802-29},
	DOI = {10.1257/aer.20161852},
	URL = {https://www.aeaweb.org/articles?id=10.1257/aer.20161852}}


@article{Christiano2005,
	ISSN = {00223808, 1537534X},
	URL = {http://www.jstor.org/stable/10.1086/426038},
	abstract = {We present a model embodying moderate amounts of nominal rigidities that accounts for the observed inertia in inflation and persistence in output. The key features of our model are those that prevent a sharp rise in marginal costs after an expansionary shock to monetary policy. Of these features, the most important are staggered wage contracts that have an average duration of three quarters and variable capital utilization.},
	author = {Lawrence J. Christiano and Martin Eichenbaum and Charles L. Evans},
	journal = {Journal of Political Economy},
	number = {1},
	pages = {1--45},
	publisher = {The University of Chicago Press},
	title = {Nominal Rigidities and the Dynamic Effects of a Shock to Monetary Policy},
	urldate = {2024-05-23},
	volume = {113},
	year = {2005}
}

@article{Sims1990,
	ISSN = {00129682, 14680262},
	URL = {http://www.jstor.org/stable/2938337},
	abstract = {This paper considers estimation and hypothesis testing in linear time series models when some or all of the variables have unit roots. Our motivating example is a vector autoregression with some unit roots in the companion matrix, which might include polynomials in time as regressors. In the general formulation, the variable might be integrated or cointegrated of arbitrary orders, and might have drifts as well. We show that parameters that can be written as coefficients on mean zero, nonintegrated regressors have jointly normal asymptotic distributions, converging at the rate T1/2. In general, the other coefficients (including the coefficients on polynomials in time) will have nonnormal asymptotic distributions. The results provide a formal characterization of which t or F tests--such as Granger causality tests--will be asymptotically valid, and which will have nonstandard limiting distributions.},
	author = {Christopher A. Sims and James H. Stock and Mark W. Watson},
	journal = {Econometrica},
	number = {1},
	pages = {113--144},
	publisher = {[Wiley, Econometric Society]},
	title = {Inference in Linear Time Series Models with some Unit Roots},
	urldate = {2024-05-15},
	volume = {58},
	year = {1990}
}

@book{Johansen1995,
	author = {Johansen, Søren},
	title = "{Likelihood-Based Inference in Cointegrated Vector Autoregressive Models}",
	publisher = {Oxford University Press},
	year = {1995},
	month = {12},
	abstract = "{This monograph is concerned with the statistical analysis of multivariate systems of non‐stationary time series of type I(1). It applies the concepts of cointegration and common trends in the framework of the Gaussian vector autoregressive model. The main result on the structure of cointegrated processes as defined by the error correction model is Grangers representation theorem. The statistical results include derivation of the trace test for cointegrating rank, test on cointegrating relations, and test on adjustment coefficients and their asymptotic distributions.}",
	isbn = {9780198774501},
	doi = {10.1093/0198774508.001.0001},
	url = {https://doi.org/10.1093/0198774508.001.0001},
}




@article{Johansen1991,
	ISSN = {00129682, 14680262},
	URL = {http://www.jstor.org/stable/2938278},
	abstract = {The purpose of this paper is to present the likelihood methods for the analysis of cointegration in VAR models with Gaussian errors, seasonal dummies, and constant terms. We discuss likelihood ratio tests of cointegration rank and find the asymptotic distribution of the test statistics. We characterize the maximum likelihood estimator of the cointegrating relations and formulate tests of structural hypotheses about these relations. We show that the asymptotic distribution of the maximum likelihood estimator is mixed Gaussian. Once a certain eigenvalue problem is solved and the eigenvectors and eigenvalues calculated, one can conduct inference on the cointegrating rank using some nonstandard distributions, and test hypotheses about cointegrating relations using the χ 2 distribution.},
	author = {Søren Johansen},
	journal = {Econometrica},
	number = {6},
	pages = {1551--1580},
	publisher = {[Wiley, Econometric Society]},
	title = {Estimation and Hypothesis Testing of Cointegration Vectors in Gaussian Vector Autoregressive Models},
	urldate = {2024-05-06},
	volume = {59},
	year = {1991}
}

@article{Chernozhukov2021,
	title = {Causal impact of masks, policies, behavior on early covid-19 pandemic in the U.S.},
	journal = {Journal of Econometrics},
	volume = {220},
	number = {1},
	pages = {23-62},
	year = {2021},
	note = {Pandemic Econometrics},
	issn = {0304-4076},
	doi = {https://doi.org/10.1016/j.jeconom.2020.09.003},
	url = {https://www.sciencedirect.com/science/article/pii/S0304407620303468},
	author = {Victor Chernozhukov and Hiroyuki Kasahara and Paul Schrimpf},
	keywords = {Covid-19, Causal impact, Masks, Policies, Behavior},
	abstract = {The paper evaluates the dynamic impact of various policies adopted by US states on the growth rates of confirmed Covid-19 cases and deaths as well as social distancing behavior measured by Google Mobility Reports, where we take into consideration people’s voluntarily behavioral response to new information of transmission risks in a causal structural model framework. Our analysis finds that both policies and information on transmission risks are important determinants of Covid-19 cases and deaths and shows that a change in policies explains a large fraction of observed changes in social distancing behavior. Our main counterfactual experiments suggest that nationally mandating face masks for employees early in the pandemic could have reduced the weekly growth rate of cases and deaths by more than 10 percentage points in late April and could have led to as much as 19 to 47 percent less deaths nationally by the end of May, which roughly translates into 19 to 47 thousand saved lives. We also find that, without stay-at-home orders, cases would have been larger by 6 to 63 percent and without business closures, cases would have been larger by 17 to 78 percent. We find considerable uncertainty over the effects of school closures due to lack of cross-sectional variation; we could not robustly rule out either large or small effects. Overall, substantial declines in growth rates are attributable to private behavioral response, but policies played an important role as well. We also carry out sensitivity analyses to find neighborhoods of the models under which the results hold robustly: the results on mask policies appear to be much more robust than the results on business closures and stay-at-home orders. Finally, we stress that our study is observational and therefore should be interpreted with great caution. From a completely agnostic point of view, our findings uncover predictive effects (association) of observed policies and behavioral changes on future health outcomes, controlling for informational and other confounding variables.}
}

@article{Newey1987,
	ISSN = {00129682, 14680262},
	URL = {http://www.jstor.org/stable/1913610},
	author = {Whitney K. Newey and Kenneth D. West},
	journal = {Econometrica},
	number = {3},
	pages = {703--708},
	publisher = {[Wiley, Econometric Society]},
	title = {A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix},
	urldate = {2024-03-13},
	volume = {55},
	year = {1987}
}

@article{Elliott1996,
	ISSN = {00129682, 14680262},
	URL = {http://www.jstor.org/stable/2171846},
	abstract = {The asymptotic power envelope is derived for point-optimal tests of a unit root in the autoregressive representation of a Gaussian time series under various trend specifications. We propose a family of tests whose asymptotic power functions are tangent to the power envelope at one point and are never far below the envelope. When the series has no deterministic component, some previously proposed tests are shown to be asymptotically equivalent to members of this family. When the series has an unknown mean or linear trend, commonly used tests are found to be dominated by members of the family of point-optimal invariant tests. We propose a modified version of the Dickey-Fuller t test which has substantially improved power when an unknown mean or trend is present. A Monte Carlo experiment indicates that the modified test works well in small samples.},
	author = {Graham Elliott and Thomas J. Rothenberg and James H. Stock},
	journal = {Econometrica},
	number = {4},
	pages = {813--836},
	publisher = {[Wiley, Econometric Society]},
	title = {Efficient Tests for an Autoregressive Unit Root},
	urldate = {2024-03-13},
	volume = {64},
	year = {1996}
}


@article{Phillips1988,
	ISSN = {00063444},
	URL = {http://www.jstor.org/stable/2336182},
	abstract = {This paper proposes new tests for detecting the presence of a unit root in quite general time series models. Our approach is nonparametric with respect to nuisance parameters and thereby allows for a very wide class of weakly dependent and possibly heterogeneously distributed data. The tests accommodate models with a fitted drift and a time trend so that they may be used to discriminate between unit root nonstationarity and stationarity about a deterministic trend. The limiting distributions of the statistics are obtained under both the unit root null and a sequence of local alternatives. The latter noncentral distribution theory yields local asymptotic power functions for the tests and facilitates comparisons with alternative procedures due to Dickey & Fuller. Simulations are reported on the performance of the new tests in finite samples.},
	author = {Peter C. B. Phillips and Pierre Perron},
	journal = {Biometrika},
	number = {2},
	pages = {335--346},
	publisher = {[Oxford University Press, Biometrika Trust]},
	title = {Testing for a Unit Root in Time Series Regression},
	urldate = {2024-03-13},
	volume = {75},
	year = {1988}
}


@article{Beveridge1981,
	title = {A new approach to decomposition of economic time series into permanent and transitory components with particular attention to measurement of the ‘business cycle’},
	journal = {Journal of Monetary Economics},
	volume = {7},
	number = {2},
	pages = {151-174},
	year = {1981},
	issn = {0304-3932},
	doi = {https://doi.org/10.1016/0304-3932(81)90040-4},
	url = {https://www.sciencedirect.com/science/article/pii/0304393281900404},
	author = {Stephen Beveridge and Charles R. Nelson},
	abstract = {This paper introduces a general procedure for decomposition of non-stationary time series into a permanent and transitory component allowing both components to be stochastic. The permanent component is shown to be a random walk with drift and the transitory or cyclical component is a stationary process with mean zero. The decomposition methodology, which depends only on past data and therefore is computable in ‘real time’, is applied to the problem of measuring and dating business ‘cycles’ in the portwar U.S. economy. We find that measured expansions and contractions are of roughly equivalent duration and that our dating of cyclical episodes tends to lead the traditional NBER dating and, to a lesser extent, the ‘growth cycle’ chronology of Zarnowitz and Boschan (1977).}
}

@BOOK{Shumway2017,
	title     = "Time series analysis and its applications",
	author    = "Shumway, Robert H and Stoffer, David S",
	publisher = "Springer International Publishing",
	series    = "Springer Texts in Statistics",
	edition   =  4,
	month     =  apr,
	year      =  2017,
	address   = "Basel, Switzerland",
	language  = "en"
}

@BOOK{Tsay2013,
	title     = "Multivariate time series analysis",
	author    = "Tsay, Ruey S",
	publisher = "John Wiley \& Sons",
	series    = "Wiley Series in Probability and Statistics",
	month     =  nov,
	year      =  2013,
	address   = "Nashville, TN",
	language  = "en"
}

@BOOK{Tsay2010,
	title     = "Analysis of financial time series",
	author    = "Tsay, Ruey S",
	publisher = "Wiley-Blackwell",
	edition   =  3,
	month     =  aug,
	year      =  2010,
	address   = "Hoboken, NJ",
	language  = "en"
}

@BOOK{Tsay2012,
	title     = "An introduction to analysis of financial data with {R}",
	author    = "Tsay, Ruey S",
	publisher = "Wiley-Blackwell",
	series    = "Wiley Series in Probability and Statistics",
	month     =  oct,
	year      =  2012,
	address   = "Hoboken, NJ",
	language  = "en"
}





@BOOK{Enders2014,
	title     = "Applied Econometric Time Series",
	author    = "Enders, Walter",
	publisher = "John Wiley \& Sons",
	series    = "Wiley Series in Probability and Statistics",
	edition   =  4,
	month     =  oct,
	year      =  2014,
	address   = "Nashville, TN"
}

@BOOK{Hamilton1994,
	title     = "Time series analysis",
	author    = "Hamilton, James Douglas",
	publisher = "Princeton University Press",
	month     =  jan,
	year      =  1994,
	address   = "Princeton, NJ",
	language  = "en"
}



@article{Carrasco2002,
	ISSN = {02664666, 14694360},
	URL = {http://www.jstor.org/stable/3533024},
	abstract = {This paper first provides some useful results on a generalized random coefficient autoregressive model and a generalized hidden Markov model. These results simultaneously imply strict stationarity, existence of higher order moments, geometric ergodicity, and β-mixing with exponential decay rates, which are important properties for statistical inference. As applications, we then provide easy-to-verify sufficient conditions to ensure β-mixing and finite higher order moments for various linear and nonlinear GARCH(1,1), linear and power GARCH(p,q), stochastic volatility, and autoregressive conditional duration models. For many of these models, our sufficient conditions for existence of second moments and exponential β-mixing are also necessary. For several GARCH(1,1) models, our sufficient conditions for existence of higher order moments again coincide with the necessary ones in He and Terasvirta.},
	author = {Marine Carrasco and Xiaohong Chen},
	journal = {Econometric Theory},
	number = {1},
	pages = {17--39},
	publisher = {Cambridge University Press},
	title = {Mixing and Moment Properties of Various GARCH and Stochastic Volatility Models},
	urldate = {2024-02-23},
	volume = {18},
	year = {2002}
}


@techreport{Heckman2022,
	title = "Causality and Econometrics",
	author = "Heckman, James J and Pinto, Rodrigo",
	institution = "National Bureau of Economic Research",
	type = "Working Paper",
	series = "Working Paper Series",
	number = "29787",
	year = "2022",
	month = "February",
	doi = {10.3386/w29787},
	URL = "http://www.nber.org/papers/w29787",
	abstract = {This paper examines the econometric causal model for policy analysis developed by the seminal ideas of Ragnar Frisch and Trygve Haavelmo. We compare the econometric causal model with two popular causal frameworks: Neyman-Holland causal model and the do-calculus. The Neyman-Holland causal model is based on the language of potential outcomes and was largely developed by statisticians. The do-calculus, developed by Judea Pearl and co-authors, relies on Directed Acyclic Graphs (DAGs) and is a popular causal framework in computer science. We make the case that economists who uncritically use these approximating frameworks often discard the substantial benefits of the econometric causal model to the detriment of more informative economic policy analyses. We illustrate the versatility and capabilities of the econometric framework using causal models that are frequently studied by economists.},
}


@article{Dickey1979,
	ISSN = {01621459},
	URL = {http://www.jstor.org/stable/2286348},
	abstract = {Let n observations Y1, Y2, ..., Yn be generated by the model Yt = ρ Yt - 1 + et, where Y0 is a fixed constant and {et}t = 1n is a sequence of independent normal random variables with mean 0 and variance σ2. Properties of the regression estimator of ρ are obtained under the assumption that ρ = ± 1. Representations for the limit distributions of the estimator of ρ and of the regression t test are derived. The estimator of ρ and the regression t test furnish methods of testing the hypothesis that ρ = 1.},
	author = {David A. Dickey and Wayne A. Fuller},
	journal = {Journal of the American Statistical Association},
	number = {366},
	pages = {427--431},
	publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
	title = {Distribution of the Estimators for Autoregressive Time Series With a Unit Root},
	volume = {74},
	year = {1979}
}

@article{Dickey1981,
	ISSN = {00129682, 14680262},
	URL = {http://www.jstor.org/stable/1912517},
	abstract = {Let the time series Yt satisfy $Y_{t}=\alpha +\rho Y_{t-1}+e_{t}$, where Y1 is fixed and the et are normal independent (0, σ 2) random variables. The likelihood ratio test of the hypothesis that (α, ρ) = (0, 1) is investigated and a limit representation for the test statistic is presented. Percentage points for the limiting distribution and for finite sample distributions are estimated. The distribution of the least squares estimator of α is also discussed. A similar investigation is conducted for the model containing a time trend.},
	author = {David A. Dickey and Wayne A. Fuller},
	journal = {Econometrica},
	number = {4},
	pages = {1057--1072},
	publisher = {[Wiley, Econometric Society]},
	title = {Likelihood Ratio Statistics for Autoregressive Time Series with a Unit Root},
	volume = {49},
	year = {1981}
}

@article{Ng2001,
	author = {Ng, Serena and Perron, Pierre},
	title = {LAG Length Selection and the Construction of Unit Root Tests with Good Size and Power},
	journal = {Econometrica},
	volume = {69},
	number = {6},
	pages = {1519-1554},
	keywords = {Integrated processes, truncation lag, GLS detrending, information criteria},
	doi = {https://doi.org/10.1111/1468-0262.00256},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-0262.00256},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1468-0262.00256},
	abstract = {It is widely known that when there are errors with a moving-average root close to −1, a high order augmented autoregression is necessary for unit root tests to have good size, but that information criteria such as the AIC and the BIC tend to select a truncation lag (k) that is very small. We consider a class of Modified Information Criteria (MIC) with a penalty factor that is sample dependent. It takes into account the fact that the bias in the sum of the autoregressive coefficients is highly dependent on k and adapts to the type of deterministic components present. We use a local asymptotic framework in which the moving-average root is local to −1 to document how the MIC performs better in selecting appropriate values of k. In Monte-Carlo experiments, the MIC is found to yield huge size improvements to the DFGLS and the feasible point optimal PT test developed in Elliott, Rothenberg, and Stock (1996). We also extend the M tests developed in Perron and Ng (1996) to allow for GLS detrending of the data. The MIC along with GLS detrended data yield a set of tests with desirable size and power properties.},
	year = {2001}
}

@article{DeLivera2012,
	author = {Alysha M. De Livera and Rob J. Hyndman and Ralph D. Snyder},
	title = {Forecasting Time Series With Complex Seasonal Patterns Using Exponential Smoothing},
	journal = {Journal of the American Statistical Association},
	volume = {106},
	number = {496},
	pages = {1513-1527},
	year = {2011},
	publisher = {Taylor & Francis},
	doi = {10.1198/jasa.2011.tm09771},
	
	
	URL = { 
	
	https://doi.org/10.1198/jasa.2011.tm09771
	
	
	
	},
	eprint = { 
	
	https://doi.org/10.1198/jasa.2011.tm09771
	
	
	
	}
	
}

@article{Ravn2002,
	author = {Ravn, Morten O. and Uhlig, Harald},
	title = "{On Adjusting the Hodrick-Prescott Filter for the Frequency of Observations}",
	journal = {The Review of Economics and Statistics},
	volume = {84},
	number = {2},
	pages = {371-376},
	year = {2002},
	month = {05},
	abstract = "{This paper studies how the Hodrick-Prescott filter should be adjusted when changing the frequency of observations. It complements the results of Baxter and King (1999) with an analytical analysis, demonstrating that the filter parameter should be adjusted by multiplying it with the fourth power of the observation frequency ratios. This yields an HP parameter value of 6.25 for annual data given a value of 1600 for quarterly data. The relevance of the suggestion is illustrated empirically.}",
	issn = {0034-6535},
	doi = {10.1162/003465302317411604},
	url = {https://doi.org/10.1162/003465302317411604},
	eprint = {https://direct.mit.edu/rest/article-pdf/84/2/371/1613390/003465302317411604.pdf},
}

@article{Said1984,
	ISSN = {00063444},
	URL = {http://www.jstor.org/stable/2336570},
	abstract = {Recently, methods for detecting unit roots in autoregressive and autoregressive-moving average time series have been proposed. The presence of a unit root indicates that the time series is not stationary but that differencing will reduce it to stationarity. The tests proposed to data require specification of the number of autoregressive and moving average coefficients in the model. In this paper we develop a test for unit roots which is based on an approximation of an autoregressive-moving average model by an autoregression. The test statistic is standard output from most regression programs and has a limit distribution whose percentiles have been tabulated. An example is provided.},
	author = {Said E. Said and David A. Dickey},
	journal = {Biometrika},
	number = {3},
	pages = {599--607},
	publisher = {[Oxford University Press, Biometrika Trust]},
	title = {Testing for Unit Roots in Autoregressive-Moving Average Models of Unknown Order},
	volume = {71},
	year = {1984}
}




@article{Hamilton2019,
	author = {Hamilton, James D.},
	title = "{Why You Should Never Use the Hodrick-Prescott Filter}",
	journal = {The Review of Economics and Statistics},
	volume = {100},
	number = {5},
	pages = {831-843},
	year = {2018},
	month = {12},
	abstract = "{Here’s why. (a) The Hodrick-Prescott (HP) filter introduces spurious dynamic relations that have no basis in the underlying data-generating process. (b) Filtered values at the end of the sample are very different from those in the middle and are also characterized by spurious dynamics. (c) A statistical formalization of the problem typically produces values for the smoothing parameter vastly at odds with common practice. (d) There is a better alternative. A regression of the variable at date t on the four most recent values as of date t - h achieves all the objectives sought by users of the HP filter with none of its drawbacks.}",
	issn = {0034-6535},
	doi = {10.1162/rest_a_00706},
	url = {https://doi.org/10.1162/rest\_a\_00706},
	eprint = {https://direct.mit.edu/rest/article-pdf/100/5/831/1918879/rest\_a\_00706.pdf},
}
 
 

@article{Dickey1987,
	ISSN = {07350015},
	URL = {http://www.jstor.org/stable/1391997},
	abstract = {One way of handling nonstationarity in time series is to compute first differences and fit a model to the differenced series unless the differenced series also looks nonstationary. In that case, second- or higher-order differencing is done. To decide if the current degree of differencing is sufficient, one can look at the autocorrelation function for slow decay. A formal statistical test for the need to difference further is available if one is willing to assume that at most one more difference will render the series stationary. In this article, we present a proper sequence of statistical tests that allows the practitioner to handle cases in which a high order of differencing may be needed. The proper sequence is not the traditional sequence, which begins with a test for a single unit root.},
	author = {David A. Dickey and Sastry G. Pantula},
	journal = {Journal of Business \& Economic Statistics},
	number = {4},
	pages = {455--461},
	publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
	title = {Determining the Order of Differencing in Autoregressive Processes},
	urldate = {2024-03-17},
	volume = {5},
	year = {1987}
}






@article{Diebold2015,
	author = {Francis X. Diebold},
	title = {Comparing Predictive Accuracy, Twenty Years Later: A Personal Perspective on the Use and Abuse of Diebold–Mariano Tests},
	journal = {Journal of Business \& Economic Statistics},
	volume = {33},
	number = {1},
	pages = {1--1},
	year = {2015},
	publisher = {Taylor \& Francis},
	doi = {10.1080/07350015.2014.983236},
	
	
	URL = { 
	
	https://doi.org/10.1080/07350015.2014.983236
	
	
	
	},
	eprint = { 
	
	https://doi.org/10.1080/07350015.2014.983236
	
	
	
	}
	
}


@article{Menchetti2022,
	author = {Menchetti, Fiammetta and Cipollini, Fabrizio and Mealli, Fabrizia},
	title = "{Combining counterfactual outcomes and ARIMA models for policy evaluation}",
	journal = {The Econometrics Journal},
	volume = {26},
	number = {1},
	pages = {1-24},
	year = {2022},
	month = {09},
	abstract = "{The Rubin Causal Model (RCM) is a framework that allows to define the causal effect of an intervention as a contrast of potential outcomes. In recent years, several methods have been developed under the RCM to estimate causal effects in time series settings. None of these makes use of autoregressive integrated moving average (ARIMA) models, which are instead very common in the econometrics literature. In this paper, we propose a novel approach, named Causal-ARIMA (C-ARIMA), to define and estimate the causal effect of an intervention in observational time series settings under the RCM. We first formalise the assumptions enabling the definition, the estimation and the attribution of the effect to the intervention. We then check the validity of the proposed method with a simulation study. In the empirical application, we use C-ARIMA to assess the causal effect of a permanent price reduction on supermarket sales. The CausalArima R package provides an implementation of the proposed approach.}",
	issn = {1368-4221},
	doi = {10.1093/ectj/utac024},
	url = {https://doi.org/10.1093/ectj/utac024},
	eprint = {https://academic.oup.com/ectj/article-pdf/26/1/1/48597685/utac024.pdf},
}

@article{EngleGranger1987,
	ISSN = {00129682, 14680262},
	URL = {http://www.jstor.org/stable/1913236},
	abstract = {The relationship between co-integration and error correction models, first suggested in Granger (1981), is here extended and used to develop estimation procedures, tests, and empirical examples. If each element of a vector of time series xt first achieves stationarity after differencing, but a linear combination $\alpha ^{\prime }x_{t}$ is already stationary, the time series xt are said to be co-integrated with co-integrating vector α. There may be several such co-integrating vectors so that α becomes a matrix. Interpreting $\alpha ^{\prime }x_{t}=0$ as a long run equilibrium, co-integration implies that deviations from equilibrium are stationary, with finite variance, even though the series themselves are nonstationary and have infinite variance. The paper presents a representation theorem based on Granger (1983), which connects the moving average, autoregressive, and error correction representations for co-integrated systems. A vector autoregression in differenced variables is incompatible with these representations. Estimation of these models is discussed and a simple but asymptotically efficient two-step estimator is proposed. Testing for co-integration combines the problems of unit root tests and tests with parameters unidentified under the null. Seven statistics are formulated and analyzed. The critical values of these statistics are calculated based on a Monte Carlo simulation. Using these critical values, the power properties of the tests are examined and one test procedure is recommended for application. In a series of examples it is found that consumption and income are co-integrated, wages and prices are not, short and long interest rates are, and nominal GNP is co-integrated with M2, but not M1, M3, or aggregate liquid assets.},
	author = {Robert F. Engle and C. W. J. Granger},
	journal = {Econometrica},
	number = {2},
	pages = {251--276},
	publisher = {[Wiley, Econometric Society]},
	title = {Co-Integration and Error Correction: Representation, Estimation, and Testing},
	urldate = {2024-05-02},
	volume = {55},
	year = {1987}
}

@article{Phillips1990,
	ISSN = {00129682, 14680262},
	URL = {http://www.jstor.org/stable/2938339},
	abstract = {This paper develops an asymptotic theory for residual based tests for cointegration. These tests involve procedures that are designed to detect the presence of a unit root in the residuals of (cointegrating) regressions among the levels of economic time series. Attention is given to the augmented Dickey-Fuller (ADF) test that is recommended by Engle-Granger (1987) and the Zα and Zt unit root tests recently proposed by Phillips (1987). Two new tests are also introduced, one of which is invariant to the normalization of the cointegrating regression. All of these tests are shown to be asymptotically similar and simple representations of their limiting distributions are given in terms of standard Brownian motion. The ADF and Zt tests are asymptotically equivalent. Power properties of the tests are also studied. The analysis shows that all the tests are consistent if suitably constructed but that the ADF and Zt tests have slower rates of divergence under cointegration than the other tests. This indicates that, at least in large samples, the Zα test should have superior power properties. The paper concludes by addressing the larger issue of test formulation. Some major pitfalls are discovered in procedures that are designed to test a null of cointegration (rather than no cointegration). These defects provide strong arguments against the indiscriminate use of such test formulations and support the continuing use of residual based unit root tests. A full set of critical values for residual based tests is included. These allow for demeaned and detrended data and cointegrating regressions with up to five variables.},
	author = {P. C. B. Phillips and S. Ouliaris},
	journal = {Econometrica},
	number = {1},
	pages = {165--193},
	publisher = {[Wiley, Econometric Society]},
	title = {Asymptotic Properties of Residual Based Tests for Cointegration},
	urldate = {2024-05-02},
	volume = {58},
	year = {1990}
}

