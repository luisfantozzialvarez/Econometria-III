dados
predicoes = predict(modelo, ci = 0.95)
predicoes$fcst
predicoes$fcst$dados.juros
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/Econometria-III/codigos/Modelos_Var")
library("CADFtest")
library("car")
library("lmtest")
library("sandwich")
#Pacote para VAR
library("vars")
exp = read.csv("expectativas.csv")
exp = ts(exp[,2], start = c(exp[1,1]%/%1,exp[1,1]%%1*100), frequency = 12)
juros = read.csv("selic.csv")
juros = ts(juros[,2], start = c(juros[1,1]%/%1,juros[1,1]%%1*100), frequency = 12)
infl = read.csv("nucleo_ipca.csv")
infl = ts(infl[,2], start = c(infl[1,1]%/%1,infl[1,1]%%1*100), frequency = 12)
#Anualizando variação mensal
infl=100*((1+infl/100)^(12)-1)
dados = cbind(exp, juros, infl)
dados = window(dados, start = c(2001,07), end = c(2024,03))
#Vamos analisar as FACs dos processos, para detectar a presença de sazonalidade.
#Note que os dois primeiros processos devem ser detrended
resid = residuals(lm(dados[,1:2]~ trnd))
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/Econometria-III/codigos/Modelos_Var")
library("CADFtest")
library("car")
library("lmtest")
library("sandwich")
#Pacote para VAR
library("vars")
exp = read.csv("expectativas.csv")
exp = ts(exp[,2], start = c(exp[1,1]%/%1,exp[1,1]%%1*100), frequency = 12)
juros = read.csv("selic.csv")
juros = ts(juros[,2], start = c(juros[1,1]%/%1,juros[1,1]%%1*100), frequency = 12)
infl = read.csv("nucleo_ipca.csv")
infl = ts(infl[,2], start = c(infl[1,1]%/%1,infl[1,1]%%1*100), frequency = 12)
#Anualizando variação mensal
infl=100*((1+infl/100)^(12)-1)
dados = cbind(exp, juros, infl)
dados = window(dados, start = c(2001,07), end = c(2024,03))
#Vamos analisar as FACs dos processos, para detectar a presença de sazonalidade.
#Note que os dois primeiros processos devem ser detrended
trnd = 1:nrow(dados)
resid = residuals(lm(dados[,1:2]~ trnd))
dados = cbind(dados,resid)
colnames(dados)[4:5] = paste("r", c("exp","juros"), sep="_")
#Modelo VAR estimado em aula, com dados até mar/24
modelo = VAR(dados[,1:3],type = 'both', p = 14)
#Note a ordenação das variáveis
print(colnames(dados[,1:3]))
#Vamos criar o vetor com as divulgações
divulgacoes = c(3.5781,10.65)
#Predições do modelo VAR, com dados até mar/24
predicoes = predict(modelo, ci = 0.95)
#Calculando atualização das projeções para abril
eup = summary(modelo)$covres[1:2,]%*%solve(summary(modelo)$covres[2,2])%*%(at - c(predicoes$fcst$[1,1])
predicoes$endog
summary(modelo)$covres[1:2,]%*%solve(summary(modelo)$covres[1:2,1:2])%*%(divulgacoes - c(predicoes$fcst$dados.exp[1,1],predicoes$fcst$dados.juros[1,1]))
t(summary(modelo)$covres[1:2,])%*%solve(summary(modelo)$covres[1:2,1:2])%*%(divulgacoes - c(predicoes$fcst$dados.exp[1,1],predicoes$fcst$dados.juros[1,1]))
eup = t(summary(modelo)$covres[1:2,])%*%solve(summary(modelo)$covres[1:2,1:2])%*%(divulgacoes - c(predicoes$fcst$dados.exp[1,1],predicoes$fcst$dados.juros[1,1]))
sapply(predicoes$fcst, function(x) x[1,1])
sapply(predicoes$fcst, function(x) x[1,1])+eup
rbind(dados[,1:3], sapply(predicoes$fcst, function(x) x[1,1])+eup)
sapply(predicoes$fcst, function(x) x[1,1])+eup
antigas = t(sapply(predicoes$fcst, function(x) x[1,1]))
print(antigas)
antigas = t(sapply(predicoes$fcst, function(x) x[1,1]))
print(antigas)
#Após divulgação, projeções passam a ser
novas = antigas+eup
eup
novas = antigas+t(eup)
print(novas)
base_atualizada = rbind(dados[,1:3], novas)
base_atualizada
atualizadas = predict(VAR(base_atualizada[,1:3],type = 'both', p = 14))
atualizadas
print(atualizadas_maio)
#Projeçòes para maio em diante
atualizadas_maio = predict(VAR(base_atualizada[,1:3],type = 'both', p = 14))
print(atualizadas_maio)
causality(modelo, cause = c("dados.exp", "dados.juros"))
setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
cpi = read.csv('dados/cpi.csv')
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
cpi = read.csv('dados/cpi.csv')
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
cpi = read.csv('dados/cpi.csv')
cpi = read.csv('dados/cpi.csv')
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
cpi = read.csv('dados/cpi.csv')
setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
knitr::opts_chunk$set(echo = TRUE)
#setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
cpi = read.csv('dados/cpi.csv')
cpi
View(cpi)
cpi = read.csv2('dados/cpi.csv')
cpi
ipca = read.csv2('dados/ipca.csv')
ipca
View(ipca)
ipca = read.csv('dados/ipca.csv')
View(ipca)
read.csv('dados/ipca.csv')
cpi = read.csv2('dados/cpi.csv')
cpi
strsplit(cpi[1,1],'-')
cpi = read.csv2('dados/cpi.csv')
cpi = ts(cpi[,2], start=strsplit(cpi[1,1],'-')[[1]][1:2], freq=12)
cpi
ipca = read.csv('dados/ipca.csv')
ipca
ipca[,1]
ipca = read.csv('dados/ipca.csv')
ipca = ts(log(ipca[,2]), start=strsplit(ipca[1,1],'-')[[1]], freq=12)
ipca = ts(log(ipca[,2]), start=strsplit(ipca[1,1],'.')[[1]], freq=12)
ipca[1,1]
as.character(ipca[1,1])
ipca = ts(log(ipca[,2]), start=strsplit(as.character(ipca[1,1]),'.')[[1]], freq=12)
strsplit(as.character(ipca[1,1]),'.')[[1]]
strsplit(as.character(ipca[1,1]),'[.]')[[1]]
ipca = ts(log(ipca[,2]), start=strsplit(as.character(ipca[1,1]),'[.]')[[1]], freq=12)
ipca
tx_cambio = read.csv('dados/tx_cambio.csv')
tx_cambio
tx_cambio[,2]
tx_cambio = read.csv2('dados/tx_cambio.csv')
tx_cambio[,1]
cambio = read.csv2('dados/tx_cambio.csv')
cambio = ts(log(cambio[,2]), start=strsplit(as.character(cambio[1,1]),'[.]')[[1]], freq=12)
cambio
cambio = read.csv2('dados/tx_cambio.csv')
cambio[,2]
cpi = read.csv2('dados/cpi.csv')
cpi = ts(log(cpi[,2]), start=strsplit(cpi[1,1],'-')[[1]][1:2], freq=12)
ipca = read.csv('dados/ipca.csv')
ipca = ts(log(ipca[,2]), start=strsplit(as.character(ipca[1,1]),'[.]')[[1]], freq=12)
cambio = read.csv2('dados/tx_cambio.csv')
cambio = ts(log(cambio[,2]), start=strsplit(as.character(cambio[1,1]),'[.]')[[1]], freq=12)
dados = cbind(cpi,ipca,cambio)
cpi = read.csv2('dados/cpi.csv')
cpi = ts(log(cpi[,2]), start=strsplit(cpi[1,1],'-')[[1]][1:2], freq=12)
ipca = read.csv('dados/ipca.csv')
ipca = ts(log(ipca[,2]), start=strsplit(as.character(ipca[1,1]),'[.]')[[1]], freq=12)
cambio = read.csv2('dados/tx_cambio.csv')
cambio = ts(log(cambio[,2]), start=strsplit(as.character(cambio[1,1]),'[.]')[[1]], freq=12)
dados = cbind(cpi,ipca,cambio)
dados = window(dados, start = c(2001,12))
plot(dados)
#Vamos considerar os testes
library(CADFtest)
library(sandwich)
library(lmtest)
teste = CADFtest(dados[,1], type = "trend", max.lag.y = ceiling(12*(length(dados[,1])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
linearHypothesis(teste$est.model,c("trnd = 0", "L(y, 1) = 0" ))
teste = CADFtest(dados[,1], type = "drift", max.lag.y = ceiling(12*(length(dados[,1])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
#Rodando o teste no modelo com drift somente
teste = CADFtest(dados[,1], type = "drift", max.lag.y = ceiling(12*(length(dados[,1])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
#Não rejeitamos a nula, aqui
#Teste F para componente determinístico
linearHypothesis(teste$est.model,c("(Intercept) = 0", "L(y, 1) = 0" ))
teste = CADFtest(dados[,1], type = "none", max.lag.y = ceiling(12*(length(dados[,1])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
#Testando pela presença de componentes determinísticos na diferença
trnd = 1:(nrow(dados)-1)
coeftest(lm(diff(dados[,1])~trnd), vcov. = vcovHAC)
linearHypothesis
#setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
#setwd("~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/Documents/GitHub/Econometria-III/exercicios/exercicios_cointegracao")
cpi = read.csv2('dados/cpi.csv')
cpi = ts(log(cpi[,2]), start=strsplit(cpi[1,1],'-')[[1]][1:2], freq=12)
ipca = read.csv('dados/ipca.csv')
ipca = ts(log(ipca[,2]), start=strsplit(as.character(ipca[1,1]),'[.]')[[1]], freq=12)
cambio = read.csv2('dados/tx_cambio.csv')
cambio = ts(log(cambio[,2]), start=strsplit(as.character(cambio[1,1]),'[.]')[[1]], freq=12)
dados = cbind(cpi,ipca,cambio)
dados = window(dados, start = c(2001,12))
#Visualizando os dados
plot(dados)
#Vamos considerar os testes A 10% de significância
library(CADFtest)
library(car)
library(sandwich)
library(lmtest)
#CPI
teste = CADFtest(dados[,1], type = "trend", max.lag.y = ceiling(12*(length(dados[,1])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
#Não rejeitamos a nula, nesta etapa
#Teste F para componente determinístico
linearHypothesis(teste$est.model,c("trnd = 0", "L(y, 1) = 0" ))
#Olhando a tabela correspondente ao nosso caso nos slides, não rejeitamos a nula do teste F a 10%.
#Rodando o teste no modelo com drift somente
teste = CADFtest(dados[,1], type = "drift", max.lag.y = ceiling(12*(length(dados[,1])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
#Não rejeitamos a nula, aqui
#Teste F para componente determinístico
linearHypothesis(teste$est.model,c("(Intercept) = 0", "L(y, 1) = 0" ))
#Valor crítico a 10%, nos slides, é 3.81 (temos 269 observações). Logo, não rejeitamos a nula
#Rodando o teste no modelo sem componente determinístico
teste = CADFtest(dados[,1], type = "none", max.lag.y = ceiling(12*(length(dados[,1])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
#Conclusão: não rejeitamos a nula de raiz unitária
#Testando pela presença de componentes determinísticos na diferença
trnd = 1:(nrow(dados)-1)
coeftest(lm(diff(dados[,1])~trnd), vcov. = vcovHAC)
#Não há evidência tendência linear na diferença, mas há intercepto, ou seja,
#série se comporta como um passeio aleatório com drift (tendência estocástica + determinística)
#IPCA
teste = CADFtest(dados[,1], type = "trend", max.lag.y = ceiling(12*(length(dados[,1])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
teste = CADFtest(dados[,2], type = "trend", max.lag.y = ceiling(12*(length(dados[,2])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
dados[,2]
linearHypothesis(teste$est.model,c("trnd= 0", "L(y, 1) = 0" ))
teste = CADFtest(dados[,2], type = "drift", max.lag.y = ceiling(12*(length(dados[,2])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
dados[,2]
linearHypothesis(teste$est.model,c("(Intercept)= 0", "L(y, 1) = 0" ))
teste$statistic
summary(teste)
#Testando pela presença de componentes determinísticos na diferença
trnd = 1:(nrow(dados)-1)
coeftest(lm(diff(dados[,1])~trnd), vcov. = vcovHAC)
#Não há evidência tendência linear na diferença, mas há evidência de intercepto, ou seja,
#série se comporta como um passeio aleatório com drift (tendência estocástica + determinística)
#Testando pela presença de componentes determinísticos na diferença
trnd = 1:(nrow(dados)-1)
coeftest(lm(diff(dados[,2])~trnd), vcov. = vcovHAC)
teste = CADFtest(dados[,3], type = "trend", max.lag.y = ceiling(12*(length(dados[,2])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
teste = CADFtest(dados[,3], type = "trend", max.lag.y = ceiling(12*(length(dados[,2])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
#Não rejeitamos a nula do teste, nesta etapa
#Teste F para componente determinístico
linearHypothesis(teste$est.model,c("trnd= 0", "L(y, 1) = 0" ))
teste = CADFtest(dados[,3], type = "trend", max.lag.y = ceiling(12*(length(dados[,3])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
length(dados[,1])
teste = CADFtest(dados[,2], type = "trend", max.lag.y = ceiling(12*(length(dados[,2])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
teste = CADFtest(dados[,3], type = "trend", max.lag.y = ceiling(12*(length(dados[,3])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
dados[,3]
plot(dados[,3])
linearHypothesis(teste$est.model,c("trnd= 0", "L(y, 1) = 0" ))
teste = CADFtest(dados[,3], type = "drift", max.lag.y = ceiling(12*(length(dados[,3])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
linearHypothesis(teste$est.model,c("(Intercept)= 0", "L(y, 1) = 0" ))
teste = CADFtest(dados[,3], type = "none", max.lag.y = ceiling(12*(length(dados[,3])/100)^(1/4)),
criterion = "MAIC")
summary(teste)
#Testando pela presença de componentes determinísticos na diferença
trnd = 1:(nrow(dados)-1)
coeftest(lm(diff(dados[,3])~trnd), vcov. = vcovHAC)
colnames(dados)
modelo_nivel = lm(cpi~.,data= dados)
summary(modelo_nivel)
teste = lm(cpi~.,data= dados)
res= ts(residuals(teste),start = c(2001,12),frequency=12)
plot(res)
teste = lm(cpi~.,data= dados)
res= ts(residuals(teste),start = c(2001,12),frequency=12)
ur.pp(res, type = c("Z-tau"))
teste = lm(cpi~.,data= dados)
res= ts(residuals(teste),start = c(2001,12),frequency=12)
ur.pp(res, type = c("Z-tau"))
#Olhando a tabela dos slides, valor crítico para n=3, com drift do lado direito (Caso 3)
#a 10% é: -3.52. Logo, NÃO REJEITAMOS a nula de que não HÁ cointegração.
modelo_diff = lm(diff(cpi)~diff(ipca)+diff(cambio),data=dados)
coeftest(modelo_diff, vcov. = vcovHAC)
modelo_diff = lm(diff(cpi)~diff(ipca)+diff(cambio),data=dados)
coefci(modelo_diff, level = 0.9, vcov. = vcovHAC)
exp(dados[,3])
acf(diff(dados))
modelo_diff = lm(diff(cpi)~diff(ipca)+diff(cambio),data=dados)
coefci(modelo_diff, level = 0.9, vcov. = vcovHAC)
diff(dados)
cpi = read.csv2('dados/cpi.csv')
cpi = ts(log(cpi[,2]), start=strsplit(cpi[1,1],'-')[[1]][1:2], freq=12)
ipca = read.csv('dados/ipca.csv')
ipca = ts(log(ipca[,2]), start=strsplit(as.character(ipca[1,1]),'[.]')[[1]], freq=12)
cambio = read.csv2('dados/tx_cambio.csv')
cambio = ts(log(cambio[,2]), start=strsplit(as.character(cambio[1,1]),'[.]')[[1]], freq=12)
dados = cbind(cpi,ipca,cambio)
#Vamos parar em mar/24, quando todas as séries estão disponíveis
dados = window(dados, start = c(2001,12),end = c(2024,03))
#Visualizando os dados
plot(dados)
acf(diff(dados),lag.max=48)
ceiling(12*(length(dados[,3])/100)^(1/4))
help("VARselect")
VARselect(DADOS, lag.max = 20, type = 'const')
VARselect(dados, lag.max = 20, type = 'const')
var = VAR(dados, p=3, type = 'const')
lkl = 2*(logLik(var) - logLik(VAR(dados, p=2, type = 'const')))
#Teste de razão de verossimilhança para a nula de que última defasagem é irrelevante
lkl = 2*(logLik(var) - logLik(VAR(dados, p=2, type = 'const')))
#Rejeitaremos nula a 10% se lkl maior que o valor crítico, isto é, se:
lkl > qchisq(0.9, 9)
lkl
qchisq(0.9, 9)
#Selecionando a ordem p
VARselect(dados, lag.max = 20, type = 'const')
#Vamos escolher a ordem indicada pelo BIC
var = VAR(dados, p=2, type = 'const')
#Teste de razão de verossimilhança para a nula de que última defasagem é irrelevante
lkl = 2*(logLik(var) - logLik(VAR(dados, p=1, type = 'const')))
#Rejeitaremos nula a 10% se lkl maior que o valor crítico, isto é, se:
lkl > qchisq(0.9, 9)
lkl
#Vamos analisar a autocorrelação dos erros
serial.test(var, lags.bg = 6)
serial.test(var, lags.bg = 6)
help("serial.test")
#Vamos analisar a autocorrelação dos erros
serial.test(var, lags.bg = 6, type = 'BG')
var = VAR(dados, p=3, type = 'const')
#Teste de razão de verossimilhança para a nula de que última defasagem é irrelevante
lkl = 2*(logLik(var) - logLik(VAR(dados, p=2, type = 'const')))
#Rejeitaremos nula a 10% se lkl maior que o valor crítico, isto é, se:
lkl > qchisq(0.9, 9)
#Não há evidência estatística suficiente para afirmar que última defasagem é irrelevante
#Vamos analisar a autocorrelação dos erros
serial.test(var, lags.bg = 6, type = 'BG')
#Vamos escolher a ordem indicada pelo BIC
var = VAR(dados, p=4, type = 'const')
#Teste de razão de verossimilhança para a nula de que última defasagem é irrelevante
lkl = 2*(logLik(var) - logLik(VAR(dados, p=3, type = 'const')))
#Rejeitaremos nula a 10% se lkl maior que o valor crítico, isto é, se:
lkl > qchisq(0.9, 9)
#Não há evidência estatística suficiente para afirmar que última defasagem é irrelevante
#Vamos analisar a autocorrelação dos erros
serial.test(var, lags.bg = 6, type = 'BG')
#Vamos escolher a ordem indicada pelo BIC
var = VAR(dados, p=4, type = 'const')
#Teste de razão de verossimilhança para a nula de que última defasagem é irrelevante
lkl = 2*(logLik(var) - logLik(VAR(dados, p=3, type = 'const')))
#Rejeitaremos nula a 10% se lkl maior que o valor crítico, isto é, se:
lkl > qchisq(0.9, 9)
#Não há evidência estatística suficiente para afirmar que última defasagem é irrelevante
#Vamos analisar a autocorrelação dos erros
serial.test(var, lags.bg = 6, type = 'BG')
#Selecionando a ordem p
VARselect(dados, lag.max = 20, type = 'const')
#Vamos escolher a ordem indicada pelo BIC
var = VAR(dados, p=2, type = 'const')
#Teste de razão de verossimilhança para a nula de que última defasagem é irrelevante
lkl = 2*(logLik(var) - logLik(VAR(dados, p=1, type = 'const')))
#Rejeitaremos nula a 10% se lkl maior que o valor crítico, isto é, se:
lkl > qchisq(0.9, 9)
#Logo, rejeitamos a nula.
#Vamos analisar a autocorrelação dos erros
serial.test(var, lags.bg = 6, type = 'BG')
#Teste claramente rejeita a nula. Vamos incluir uma defasagem adicional para ver se há melhora.
#Vamos escolher a ordem indicada pelo BIC
var = VAR(dados, p=3, type = 'const')
#Teste de razão de verossimilhança para a nula de que última defasagem é irrelevante
lkl = 2*(logLik(var) - logLik(VAR(dados, p=2, type = 'const')))
#Rejeitaremos nula a 10% se lkl maior que o valor crítico, isto é, se:
lkl > qchisq(0.9, 9)
#Não há evidência estatística suficiente para afirmar que última defasagem é irrelevante
#Vamos analisar a autocorrelação dos erros
serial.test(var, lags.bg = 6, type = 'BG')
#No entanto, teste passa a não rejeitar a nula de não autocorrelação a 1%
#Vamos ficar com esta ordem, pois melhora substancialmente a conclusão do teste de não autocorrelação.
serial.test(var, lags.bg = 6, type = 'PT.adjusted')
serial.test(var, lags.bg = 6, type = 'PT.adjusted')
#Selecionando a ordem p
VARselect(dados, lag.max = 20, type = 'const')
#Vamos escolher a ordem indicada pelo BIC
var = VAR(dados, p=2, type = 'const')
#Teste de razão de verossimilhança para a nula de que última defasagem é irrelevante
lkl = 2*(logLik(var) - logLik(VAR(dados, p=1, type = 'const')))
#Rejeitaremos nula a 10% se lkl maior que o valor crítico, isto é, se:
lkl > qchisq(0.9, 9)
serial.test(var, lags.bg = 6, type = 'BG')
serial.test(var,  type = 'PT.adjusted')
#Selecionando a ordem p
VARselect(dados, lag.max = 20, type = 'const')
#Vamos escolher a ordem indicada pelo BIC
var = VAR(dados, p=2, type = 'const')
#Teste de razão de verossimilhança para a nula de que última defasagem é irrelevante
lkl = 2*(logLik(var) - logLik(VAR(dados, p=1, type = 'const')))
#Rejeitaremos nula a 10% se lkl maior que o valor crítico, isto é, se:
lkl > qchisq(0.9, 9)
#Logo, rejeitamos a nula.
#Vamos analisar a autocorrelação dos erros
serial.test(var,  type = 'BG')
#Vamos escolher a ordem indicada pelo BIC
var = VAR(dados, p=3, type = 'const')
#Teste de razão de verossimilhança para a nula de que última defasagem é irrelevante
lkl = 2*(logLik(var) - logLik(VAR(dados, p=2, type = 'const')))
#Rejeitaremos nula a 10% se lkl maior que o valor crítico, isto é, se:
lkl > qchisq(0.9, 9)
#Não há evidência estatística suficiente para afirmar que última defasagem é irrelevante
#Vamos analisar a autocorrelação dos erros
serial.test(var,  type = 'BG')
ls(teste),start = c(2001,12),frequency=12)
library("urca")
help(ca.jo)
joh = ca.jo(dados, type = 'eigen',ecdet = 'none', K = 4, spec = 'transitory')
joh = ca.jo(dados, type = 'eigen',ecdet = 'none', K = 4, spec = 'transitory')
summary(joh)
joh = ca.jo(dados, type = 'eigen',ecdet = 'trend', K = 4, spec = 'transitory')
summary(joh)
modelo = VAR(diff(dados), p=2)
modelo = VAR(diff(dados), p=2)
#Projeções para variação de preços e câmbio
predict(modelo)
trnd_level = 1:nrow(dados)
teste = lm(cpi~.+trnd_level,data= dados)
trnd_level = 1:nrow(dados)
teste = lm(cpi~cambio+ipca+trnd_level,data= dados)
summary(teste)
trnd_level = 1:nrow(dados)
teste = lm(cpi~cambio+ipca+trnd_level,data= dados)
res= ts(residuals(teste),start = c(2001,12),frequency=12)
teste = lm(cpi~.,data= dados)
res= ts(residuals(teste),start = c(2001,12),frequency=12)
library("urca")
ur.pp(res, type = c("Z-tau"))
#Olhando a tabela dos slides, valor crítico para n=3, com drift do lado direito (Caso 3)
#a 10% é: -3.52. Logo, NÃO REJEITAMOS a nula de que não HÁ cointegração.
trnd_level = 1:nrow(dados)
teste = lm(cpi~cambio+ipca+trnd_level,data= dados)
res= ts(residuals(teste),start = c(2001,12),frequency=12)
ur.pp(res, type = c("Z-tau"))
trnd_level
summary(teste)
trnd_level = 1:nrow(dados)
teste = lm(cambio~cpi+ipca+trnd_level,data= dados)
res= ts(residuals(teste),start = c(2001,12),frequency=12)
ur.pp(res, type = c("Z-tau"))
#Olhando a tabela dos slides, para TRÊS variáveis do lado direito, com drift do lado direito (Caso 3), temos que o valor crítico do teste a 10% é: -3.52. Logo, NÃO REJEITAMOS a nula de que não HÁ cointegração.
joh = ca.jo(dados, type = 'eigen',ecdet = 'trend', K = 4, spec = 'transitory')
summary(joh)
colnames(dados)
teste = blrtest(joh_trend, matrix(c(1,1,-1),nrow=3), r=1)
joh_trend = ca.jo(dados, type = 'eigen',ecdet = 'trend', K = 4, spec = 'transitory')
summary(joh_trend)
teste = blrtest(joh_trend, matrix(c(1,1,-1),nrow=3), r=1)
matrix(c(1,1,-1),nrow=3)
joh_trend
summary(joh_trend)
teste = blrtest(joh_trend, matrix(c(1,1,-1),nrow=3), r=1)
teste = blrtest(joh_trend, matrix(c(1,1,-1,0),nrow=3), r=1)
help("blrtest")
teste = blrtest(joh_trend, matrix(c(1,1,-1,0),nrow=4), r=1)
summary(teste)
matrix(c(c(1,1,-1,0),c(0,0,0,1)),nrow=4)
teste = blrtest(joh_trend, matrix(c(c(1,1,-1,0),c(0,0,0,1)),nrow=4), r=1)
summary(teste)
teste = blrtest(joh_trend, matrix(c(c(1,-1,1,0),c(0,0,0,1)),nrow=4), r=1)
summary(teste)
modelo = cajorls(joh_trend, r=1)
modelo$beta
modelo_vec_to_var = vec2var(joh_trend, r=1)
modelo_vec_to_var = vec2var(joh_trend, r=1)
#Predições em nível
predict(modelo_vec_to_var)
joh = ca.jo(dados, type = 'trace',ecdet = 'none', K = 4, spec = 'transitory')
summary(joh)
joh = ca.jo(dados, type = 'eigen',ecdet = 'none', K = 3, spec = 'transitory')
summary(joh)
joh_trend = ca.jo(dados, type = 'eigen',ecdet = 'trend', K = 3, spec = 'transitory')
summary(joh_trend)
joh = ca.jo(dados, type = 'trace',ecdet = 'none', K = 3, spec = 'transitory')
summary(joh)
joh = ca.jo(dados, type = 'trace',ecdet = 'trend', K = 3, spec = 'transitory')
summary(joh)
joh = ca.jo(dados, type = 'eigen',ecdet = 'trend', K = 3, spec = 'transitory')
summary(joh)
joh_trend = ca.jo(dados, type = 'trace',ecdet = 'trend', K = 3, spec = 'transitory')
summary(joh_trend)
