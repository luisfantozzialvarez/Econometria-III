geo = geo)
library(did)
library(fixest)
library(Matrix)
#Computes DID parameters using Conley variance-covariance estimator
#First seven parameters correspond to Callaway and Santanna's original estimator
#Eigth parameter should be a (number of panel units) x 3 dataset, where the first column is the unit identifier,
#second column is the latitude and third column is the longitude
cs_conley_att <- function(yname, gname, idname, tname, xformla, data, est_method, geo,
confidence = 0.95)
{
data = data[order(data[,idname]),]
geo = geo[order(geo[,1]),]
out <- att_gt(yname = yname,
gname = gname,
idname = idname,
tname = tname,
xformla = xformla,
data = data,
est_method = est_method,
bstrap =F
)
out <- aggte(out, type = 'simple', bstrap = F)
#return(out)
#Grabbing influence function
if_func = as.matrix(out$inf.func[[1]])
data_analysis = data.frame('term' = as.vector(if_func),  'lat' = rep(geo[,2], times = ncol(if_func)), 'lon' =rep(geo[,3], times = ncol(if_func)))
#computing matrix
model = feols(term~1, data_analysis)
mod_conley = vcov_conley(model, lat = 'lat', lon = 'lon')
se = sqrt(diag(mod_conley))
tabla = data.frame( 'est' = out$overall.att, 'se' = se)
rownames(tabla) = NULL
critical = qnorm(1-(1-confidence)/2)
tabla$lower_ci = tabla$est - critical*tabla$se
tabla$upper_ci = tabla$est + critical*tabla$se
return(list('table' =tabla, 'vcov' = mod_conley))
}
#EXAMPLE
set.seed(123)
#Fake example using CS's dataset
data(mpdta)
#I'll create a fake latlong for each unit in this dataset
geo = data.frame("id" = unique(mpdta$countyreal), "lat" = runif(length(unique(mpdta$countyreal)),-90,90),
"lon" = runif(length(unique(mpdta$countyreal)),-180,180))
#Running
results = cs_conley_att(yname = "lemp",gname= "first.treat", idname="countyreal", tname="year", xformla = ~1,data = mpdta, est_method = "reg",
geo = geo)
results
library(did)
library(fixest)
library(Matrix)
#Computes DID parameters using Conley variance-covariance estimator
#First seven parameters correspond to Callaway and Santanna's original estimator
#Eigth parameter should be a (number of panel units) x 3 dataset, where the first column is the unit identifier,
#second column is the latitude and third column is the longitude
cs_conley_att <- function(yname, gname, idname, tname, xformla, data, est_method, geo,
confidence = 0.95)
{
data = data[order(data[,idname]),]
geo = geo[order(geo[,1]),]
out <- att_gt(yname = yname,
gname = gname,
idname = idname,
tname = tname,
xformla = xformla,
data = data,
est_method = est_method,
bstrap =F
)
out <- aggte(out, type = 'simple', bstrap = F)
#return(out)
#Grabbing influence function
if_func = as.matrix(out$inf.func[[1]])
print(dim(if_func))
data_analysis = data.frame('term' = as.vector(if_func),  'lat' = rep(geo[,2], times = ncol(if_func)), 'lon' =rep(geo[,3], times = ncol(if_func)))
#computing matrix
model = feols(term~1, data_analysis)
mod_conley = vcov_conley(model, lat = 'lat', lon = 'lon')
se = sqrt(diag(mod_conley))
tabla = data.frame( 'est' = out$overall.att, 'se' = se)
rownames(tabla) = NULL
critical = qnorm(1-(1-confidence)/2)
tabla$lower_ci = tabla$est - critical*tabla$se
tabla$upper_ci = tabla$est + critical*tabla$se
return(list('table' =tabla, 'vcov' = mod_conley))
}
#EXAMPLE
set.seed(123)
#Fake example using CS's dataset
data(mpdta)
#I'll create a fake latlong for each unit in this dataset
geo = data.frame("id" = unique(mpdta$countyreal), "lat" = runif(length(unique(mpdta$countyreal)),-90,90),
"lon" = runif(length(unique(mpdta$countyreal)),-180,180))
#Running
results = cs_conley_att(yname = "lemp",gname= "first.treat", idname="countyreal", tname="year", xformla = ~1,data = mpdta, est_method = "reg",
geo = geo)
results
# Research question and methodology
help(decompose)
37.8*1.0002
1/4
1/16
ln(2)
log(2)
log())
log(3)
log(4)
log(5)
log(10)
log(10)/10
exp(2)
devtools::install_github("gadenbuie/rsthemes")
install.packages("devtools")
install.packages("devtools")
devtools::install_github("gadenbuie/rsthemes")
rsthemes::install_rsthemes(include_base16 = TRUE)
v = matrix(c(1,0.5,0.5,2))
v
v = matrix(c(1,0.5,0.5,2),nrow=2)
chol(v)
chol(v)%*%t(chol(v))
t(chol(v))%*%chol(v)
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(5000), ncol=2)
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(5000), nrow=2)
pd
dim(pd)
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(10000), nrow=2)
pd = t(pd)
ts(pd)
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(10000), nrow=2)
pd = t(pd)
mat = ts(pd)
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(10000), nrow=2)
pd = t(pd)
mat = ts(pd)
plot(mat)
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
mat = ts(pd)
plot(mat)
plot(mat[,1])
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
mat = ts(pd)
plot(mat[,1],col='blue')
lines(mat[,2],col='red')
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
mat = ts(pd)
plot(mat,col=c('blue','red'))
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(mat,col=c('blue','red'))
help(plot.ts)
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(mat,plot.type = 'single',col=c('blue','red'))
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = chol(v)
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(mat,col=c('blue','red'))
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = t(chol(v))
a%*%t(a)
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = t(chol(v))
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(mat,col=c('blue','red'))
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = t(chol(v))
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(mat,col=c('blue','red'))
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = t(chol(v))
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(mat)
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = t(chol(v))
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(rb)
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = t(chol(v))
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(rb,col=c('blue','red'))
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = t(chol(v))
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(rb,plot.type = 'single',col=c('blue','red'))
set.seed(123)
v = matrix(c(1,0.5,0.5,2),nrow=2)
a = t(chol(v))
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(rb)
set.seed(123)
v = matrix(c(1,1,1,2),nrow=2)
a = t(chol(v))
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(rb)
set.seed(123)
v = matrix(c(1,1,1,2),nrow=2)
a = t(chol(v))
pd = a%*%matrix(rnorm(1000), nrow=2)
pd = t(pd)
rb = ts(pd)
plot(rb)
pbeta(1/2,1,2)
pbeta(1/4,2,2)
pbeta(1/4,2,2)
pbeta(1/3,1,2)
pbeta(2/5,2,5)
set.seed(123)
Tt=500
a = lapply(1:1000, function(x)
{
rw= cumsum(rnorm(Tt))
y = rw + rnorm(Tt)
data.frame('y'=y, 'x' = rw)
}
)
set.seed(123)
Tt=500
a = lapply(1:1000, function(x)
{
rw= cumsum(rnorm(Tt))
y = rw + rnorm(Tt)
ts(cbind('y'=y, 'x' = rw),start=1)
}
)
a[[1]]
sapply(a, function(d) coefficients(lm(y~x, data = d))[1])
set.seed(123)
Tt=500
a = lapply(1:1000, function(x)
{
rw= cumsum(rnorm(Tt))
y = rw + rnorm(Tt)
ts(cbind('y'=y, 'x' = rw),start=1)
}
)
slope_reg = sapply(a, function(d) coefficients(lm(y~x, data = d))[2])
slope_reg
set.seed(123)
Tt=500
gamma = 0.5
a = lapply(1:1000, function(x)
{
rw= cumsum(rnorm(Tt))
y = gamma*rw + rnorm(Tt)
ts(cbind('y'=y, 'x' = rw),start=1)
}
)
slope_reg = sapply(a, function(d) coefficients(lm(y~x, data = d))[2])
plot(slope)
set.seed(123)
Tt=500
gamma = 0.5
a = lapply(1:1000, function(x)
{
rw= cumsum(rnorm(Tt))
y = gamma*rw + rnorm(Tt)
ts(cbind('y'=y, 'x' = rw),start=1)
}
)
slope_reg = sapply(a, function(d) coefficients(lm(y~x, data = d))[2])
density(slope_reg)
plot(density(slope_reg))
set.seed(123)
Tt=500
gamma = 0.5
a = lapply(1:10000, function(x)
{
rw= cumsum(rnorm(Tt))
y = gamma*rw + rnorm(Tt)
ts(cbind('y'=y, 'x' = rw),start=1)
}
)
slope_reg = sapply(a, function(d) coefficients(lm(y~x, data = d))[2])
plot(density(slope_reg))
jarque.bera.test(slope_reg)
library(tseries)
install.packages("tseries")
library(tseries)
set.seed(123)
Tt=500
gamma = 0.5
a = lapply(1:10000, function(x)
{
rw= cumsum(rnorm(Tt))
y = gamma*rw + rnorm(Tt)
ts(cbind('y'=y, 'x' = rw),start=1)
}
)
slope_reg = sapply(a, function(d) coefficients(lm(y~x, data = d))[2])
plot(density(slope_reg))
jarque.bera.test(slope_reg)
help("jarque.bera.test")
jarque.bera.test(mean(slope_reg))
jarque.bera.test((slope_reg)-mean(slope_reg))
slope_reg
plot(density(slope_reg),title = exp('Distribuição de '~gamma))
plot(density(slope_reg),main = exp('Distribuição de '~gamma))
plot(density(slope_reg),main = expr('Distribuição de '~gamma))
plot(density(slope_reg),main = expression('Distribuição de '~gamma))
plot(density(slope_reg),main = expression('Distribuição de '~hat(gamma)~' em amostras repetidas'))
plot(density(slope_reg),main = expression('Distribuição de '~hat(gamma)~' em amostras repetidas'))
plot(density(slope_reg),main = expression('Distribuição de '~hat(gamma)~' em amostras repetidas'), xlab='')
plot(a[[1]])
plot(a[[1]],single='True')
plot(a[[1]],single=T)
help(plot.tseries)
help("plot.ts")
plot(a[[1]],plot.type='single')
plot(a[[2]],plot.type='single')
plot(a[[2]],plot.type='single',col = c('red', 'blue'))
plot(a[[3]],plot.type='single',col = c('red', 'blue'), '')
legend(c('y', 'x'), col = c('red','blue'), lty = c(1,1))
plot(a[[3]],plot.type='single',col = c('red', 'blue'))
legend('bottomright',text = c('y', 'x'), col = c('red','blue'), lty = c(1,1))
plot(a[[3]],plot.type='single',col = c('red', 'blue'))
legend('torpight',text = c('y', 'x'), col = c('red','blue'), lty = c(1,1))
plot(a[[3]],plot.type='single',col = c('red', 'blue'))
legend('torpight',legend = c('y', 'x'), col = c('red','blue'), lty = c(1,1))
plot(a[[3]],plot.type='single',col = c('red', 'blue'))
legend('topright',legend = c('y', 'x'), col = c('red','blue'), lty = c(1,1))
library(tseries)
set.seed(123)
Tt=500
gamma = 0.5
a = lapply(1:10000, function(x)
{
rw= cumsum(rnorm(Tt))
y = gamma*rw + rnorm(Tt)
ts(cbind('y'=y, 'x' = rw),start=1)
}
)
slope_reg = sapply(a, function(d) coefficients(lm(y~x, data = d))[2])
plot(a[[3]],plot.type='single',col = c('red', 'blue'), ylab = '')
legend('topright',legend = c('y', 'x'), col = c('red','blue'), lty = c(1,1))
plot(density(slope_reg),main = expression('Distribuição de '~hat(gamma)~' em amostras repetidas'), xlab='')
help(causality)
library(vars)
install.packages("vars")
library(urca)
library(vars)
vec2var
load("~/Downloads/application_add-2.RData")
vls <- sapply(grid.test, function(x) x$est$value)
order(vls)
vvls
vls
vls <- sapply(grid.test, function(x) ifelse(is.null(x$est$value), Inf, x$est$value)
)
order(vls)
grid.test[[36]]
grid.test[[36]]$est
grid.test[[36]]$model$fs
model.tail
grid.test[[36]]$est
setwd("~/Documents/GitHub/Econometria-III/codigos/Modelos_Svar")
library(vars)
for(name in c("expectativa_6","expectativa_12", "selic", "ipca", "desemprego", "ibc",
"cambio_nominal"))
{
print(name)
ddd = read.csv(paste(name,".csv",sep=""))
serie = assign(name, ts(ddd[,2], start = strsplit(as.character(ddd[1,1]),"[.]")[[1]], frequency = 12 ))
serie = window(serie, start = c(2003,01), end = c(2024,03))
assign(name, serie)
}
#Anualizando IPCA
ipca = 100*((1+ipca/100)^(12) -1)
#Trabalhando com log(IBC)
ibc = log(ibc)
#Trabalhando com log(cambio)
cambio_nominal  = log(cambio_nominal)
#De aulas anteriores, sabemos que IBC e câmbio apresentam raiz unitária e que
#Selic e expectativa são trend-stationary.
#Além disso, note que
acf(diff(ibc),lag.max=40)
# ibc apresenta sazonalidade.
# Ajustamos um VAR com variação do ibc e as demais variáveis em nível, tendência linear e
# dummies sazonais
dados = cbind(diff(ibc),  ipca,selic,expectativa_12,expectativa_6,diff(cambio_nominal))
dados = window(dados, start = c(2003,02))
VARselect(dados, lag.max =ceiling(12*(nrow(dados)/100)^(1/4)), type = "both", season=12)
#Blanchard Quah brasileiro
dados_bq = cbind(diff(ibc), diff(desemprego))
dados_bq = window(dados_bq, start= c(2012,04))
VARselect(dados_bq, lag.max=ceiling(12*(nrow(dados_bq)/100)^(1/4)), type='none',season=12)
var_bq = VAR(dados_bq,4,season=12)
mod = BQ(var_bq)
fri = irf(mod, n.ahead = 48, ci = 0.95, runs = 1, cumulative = T )
plot(fri)
fri
fri$irf
fri$irf$diff.desemprego.
setwd("~/Documents/GitHub/Econometria-III/codigos/Modelos_Svar")
library(vars)
for(name in c("expectativa_6","expectativa_12", "selic", "ipca", "desemprego", "ibc",
"cambio_nominal"))
{
print(name)
ddd = read.csv(paste(name,".csv",sep=""))
serie = assign(name, ts(ddd[,2], start = strsplit(as.character(ddd[1,1]),"[.]")[[1]], frequency = 12 ))
serie = window(serie, start = c(2003,01), end = c(2024,03))
assign(name, serie)
}
#Anualizando IPCA
ipca = 100*((1+ipca/100)^(12) -1)
#Trabalhando com log(IBC)
ibc = log(ibc)
#Trabalhando com log(cambio)
cambio_nominal  = log(cambio_nominal)
#De aulas anteriores, sabemos que IBC e câmbio apresentam raiz unitária e que
#Selic e expectativa são trend-stationary.
#Além disso, note que
acf(diff(ibc),lag.max=40)
# ibc apresenta sazonalidade.
# Ajustamos um VAR com variação do ibc e as demais variáveis em nível, tendência linear e
# dummies sazonais
dados = cbind(diff(ibc),  ipca,selic,expectativa_12,expectativa_6,diff(cambio_nominal))
dados = window(dados, start = c(2003,02))
VARselect(dados, lag.max =ceiling(12*(nrow(dados)/100)^(1/4)), type = "both", season=12)
#Vamos trabalhar com a defasagem 4, escolhida pelo AIC (vale fazer testes)
#Vamos identificar a FRI do choque monetário, sob identificação recursiva.
#No nosso caso, pol monetária reage contemporaneamente a choques na IS e na PC,
# mas atividade e inflação não respondem a choques monetários contemporaneamente
#Além disso, expectativas e câmbiorespondem contemporaneamente a choques monetários, mas
#a política monetária só reage de forma defasada às expectativas e ao câmbio
var_reduzido = VAR(dados, 4, type = "both",season=12)
#Fixando semente para as simulações usadas no cálculo dos intervalos de confiança
set.seed(123)
fri = irf(var_reduzido, impulse = "selic", n.ahead = 36, ci = 0.95, runs = 1000 )
plot(fri)
#Blanchard Quah brasileiro
dados_bq = cbind(diff(ibc), diff(desemprego))
dados_bq = window(dados_bq, start= c(2012,04))
VARselect(dados_bq, lag.max=ceiling(12*(nrow(dados_bq)/100)^(1/4)), type='none',season=12)
var_bq = VAR(dados_bq,4,season=12)
mod = BQ(var_bq)
fri = irf(mod, n.ahead = 48, ci = 0.95, runs = 1000, cumulative = T )
plot(fri)
var_bq = VAR(dados_bq,4,season=12, type = 'none')
var_bq
mod = BQ(var_bq)
mod
help("plot.varirf")
plot(fri)
help("plot.varirf")
plot(fri, 'multiple')
help("plot.varirf")
plot(fri, 'single')
summary(lm(diff(ibc)~1))
