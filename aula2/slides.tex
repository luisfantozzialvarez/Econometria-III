% !TeX document-id = {0be8c18c-9430-4e9a-bdd9-12beadebfebc}
% !TeX TXS-program:bibliography = txs:///biber
\documentclass[11pt]{beamer}
\uselanguage{portuguese}
\languagepath{portuguese}
\deftranslation[to=portuguese]{Theorem}{Teorema}
\deftranslation[to=portuguese]{theorem}{teorema}
\deftranslation[to=portuguese]{Example}{Exemplo}
\deftranslation[to=portuguese]{example}{exemplo}
\deftranslation[to=portuguese]{Lemma}{Lema}
\deftranslation[to=portuguese]{lemma}{Lema}
\deftranslation[to=portuguese]{Corollary}{Corolário}
\deftranslation[to=portuguese]{corollary}{corolário}
%\deftranslation[to=portuguese]{and}{e}

\usepackage[brazilian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{color}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{subcaption}
%\usepackage{appendixnumberbeamer}

\newenvironment{transitionframe}{
	\setbeamercolor{background canvas}{bg=yellow}
	\begin{frame}}{
	\end{frame}
}
\usetheme{default}
\usefonttheme{structuresmallcapsserif}

%% I use a beige off white for my background
\definecolor{MyBackground}{RGB}{255,253,218}
\useinnertheme[shadow]{rounded}
\setbeamercolor{block title}{bg=MyBackground}
\setbeamercolor{block body}{bg=MyBackground}
\setbeamercolor{example title}{bg=MyBackground}
\setbeamercolor{example body}{bg=MyBackground}


\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\purple}[1]{\textcolor{purple}{#1}}
\newcommand{\gray}[1]{\textcolor{gray}{#1}}
\setbeamertemplate{navigation symbols}{}
%\setbeamertemplate{page number in head/foot}[appendixframenumber]

%\usepackage{graphics}
\usepackage{graphicx}

\definecolor{blue_emph}{RGB}{0,114,178}
\definecolor{red}{RGB}{213,94,0}
\definecolor{yellow}{RGB}{240,228,66}
\definecolor{green}{RGB}{0,158,115}
\definecolor{purple}{RGB}{204,121,167}
\definecolor{orange}{RGB}{230,159,0}
\definecolor{lightblue}{RGB}{86,180,233}

%\setbeamercolor{frametitle}{fg=blue}
%\setbeamercolor{title}{fg=blue}
\setbeamertemplate{footline}[frame number]
\setbeamertemplate{navigation symbols}{} 
\setbeamertemplate{itemize items}{-}
%\setbeamercolor{itemize item}{fg=blue}
%\setbeamercolor{itemize subitem}{fg=blue}
\setbeamertemplate{enumerate items}[default]
%\setbeamercolor{enumerate subitem}{fg=blue}
\setbeamercolor{button}{bg=MyBackground,fg=blue}
\usefonttheme{structuresmallcapsserif}

%\setbeamercolor{section in toc}{fg=blue}
%\setbeamercolor{subsection in toc}{fg=red}
\setbeamersize{text margin left=1em,text margin right=1em} 


\usepackage{appendixnumberbeamer}

\usepackage[
backend=biber,
style=authoryear,
natbib=true
]{biblatex}
\addbibresource{../bibliography.bib}

\newenvironment{wideitemize}{\itemize\addtolength{\itemsep}{10pt}}{\enditemize}
\newenvironment{wideenumerate}{\enumerate\addtolength{\itemsep}{10pt}}{\endenumerate}
\newenvironment{halfwideitemize}{\itemize\addtolength{\itemsep}{0.5em}}{\enditemize}
\newenvironment{halfwideenumerate}{\enumerate\addtolength{\itemsep}{0.5em}}{\endenumerate}

\def\signed #1{{\leavevmode\unskip\nobreak\hfil\penalty50\hskip2em
		\hbox{}\nobreak\hfil(#1)%
		\parfillskip=0pt \finalhyphendemerits=0 \endgraf}}

\newsavebox\mybox
\newenvironment{aquote}[1]
{\savebox\mybox{#1}\begin{quote}}
	{\signed{\usebox\mybox}\end{quote}}



\author{Luis A. F. Alvarez}
\title{EAE1223: Econometria III}
\subtitle{Aula 2 - Processos estocásticos}
%\logo{}
%\institute{}
\date{\today}
%\subject{}
%\setbeamercovered{transparent}

\begin{document}

	\begin{frame}[plain]
	\maketitle
	\end{frame}
	\begin{frame}{Espaço de probabilidade}
		\begin{itemize}
			\item Formalmente, o conceito utilizado para se definir a noção de incerteza associada a um problema é o de {\color{blue}espaço de probabilidade}.
			\item Um espaço de probabilidade é uma tripla $(\Omega, \Sigma, \mathbb{P})$, onde:
			\begin{itemize}
				\item $\Omega$ é um conjunto, denominado {\color{blue}espaço amostral}, contendo todos as possíveis realizações da incerteza.
				\item $\Sigma$ é uma coleção de subconjuntos de $\Omega$, denominada {\color{blue}$\sigma$-álgebra}. A cada subconjunto de $\Omega$ pertencente a $\Sigma$  damos o nome de {\color{blue}evento}. Os elementos de $\Sigma$ são aqueles para os quais somos capazes de definir a incerteza.
				\item uma {\color{blue}lei de probabilidade} $\mathbb{P}$ que atribui, a cada conjunto $E \in \Sigma$, um número $\mathbb{P}[E]$ entre $0$ e $1$. A lei de probabilidade satisfaz os {\color{blue}axiomas de Kolmogorov}.
			\end{itemize}
			\item Por que não definimos a probabilidade para todo subconjunto de $\Omega$?
			\begin{halfwideitemize}
				\item \textbf{Resposta:} se $\Omega$ é ``complexo'' (por exemplo, $[0,1]$), é impossível definir uma probabilidade que satisfaça todos os axiomas de Kolmogorov para todo subconjunto do espaço.
			\end{halfwideitemize}
		\end{itemize}
	\end{frame}
	
	\begin{frame}{Exemplo}
		\begin{halfwideitemize}
			\item Considere um lançamento de um dado não viciado.
			\item Nesse caso, espaço amostral é $\Omega = \{1,2,3,4,5,6\}$.
			\item Como lançamento é não viciado, sabemos que:
			$$\mathbb{P}[\{1\}]= \mathbb{P}[\{2\}] = \mathbb{P}[\{3\}] = \mathbb{P}[\{4\}] = \mathbb{P}[\{5\}] = \mathbb{P}[\{6\}] = 1/6 \,.$$
			\item Pelos axiomas da probabilidade, segue que podemos tomar $\Sigma$ como o conjunto de todos os subconjuntos de $\Omega$, e, para qualquer $E\in \Sigma$:
			$$\mathbb{P}[E]= \mathbb{P}[\cup_{e \in E}\{e\}] = \sum_{e \in E}\mathbb{P}[\{e\}] = \frac{\# E}{6}\, ,$$
			onde $\# E$ é o número de elementos de $E$.
			\item Exemplo: probabilidade de que o lançamento dê um número par é:
			$$\mathbb{P}[\{2,4,6\}]= \frac{3}{6} = \frac{1}{2}$$
		\end{halfwideitemize}
	\end{frame}
	
	
	\begin{frame}{Variável aleatória e processo estocástico}
		\begin{halfwideitemize}
			\item Uma {\color{blue}variável aleatória} $Z$ é uma {\color{blue}função}, com domínio no espaço amostral (onde definimos a incerteza), e valores em outro espaço (para nossos fins, os reais).
			\begin{itemize}
				\item Por exemplo, $(\Omega, \Sigma, \mathbb{P})$ um espaço de probabilidade descrevendo a incerteza associada aos retornos de ativos financeiros, e $Z: \Omega \mapsto \mathbb{R}$ é a variável aleatória que representa o retorno de um fundo.
				\item Incerteza em $(\Omega, \Sigma, \mathbb{P})$ traduz-se em incerteza em $Z$, i.e. $Z$ é incerto pois o valor $\omega \in \Omega$ que ocorre é incerto.
			\end{itemize}
			\item Um {\color{blue} processo estocástico} é uma coleção de variáveis aleatórias $\{X_t: t \in \mathcal{T}\}$, com domínio no \textbf{mesmo} espaço de probabilidade e indexada por um conjunto $\mathcal{T}$
			\item Uma {\color{blue}série de tempo} é um processo estocástico indexado no tempo, i.e. $\mathcal{T}$ é um conjunto de períodos.
			\begin{halfwideitemize}
				\item Sempre tomaremos $\mathcal{T} = \mathbb{Z}$ ou $\mathcal{T}  =\mathbb{N}$.
				\item Para cada $\omega \in \Omega$, $\{ X_t(\omega): t \in \mathcal{T} \}$ é uma trajetória {\color{blue}possível} da série de tempo. Para cada $t \in \mathcal{T}$, $X_t$ é uma variável aleatória.
			\end{halfwideitemize}
		\end{halfwideitemize}
	\end{frame}
	
	\begin{frame}{Processo estocástico e incerteza}
		\begin{aquote}{\cite{Haavelmo1944}}
			From this point of view we may consider the total number of possible observations [no nosso, uma trajetória possível $\{ X_t(\omega): t \in \mathcal{T} \}$] as result of a sampling procedure, which Nature is carrying out, and which we
			merely watch as passive observers.
		\end{aquote}
	\end{frame}
	\begin{frame}{Série de tempo estritamente estacionária}
		\begin{itemize}
			\item Uma série de tempo $\{X_t: t \in \mathcal{T}\}$ é dita estritamente estacionária se, para todo $t \in \mathcal{T}$, $j\in \mathbb{N}$:
			
			$$(X_t, X_{t+1}, \ldots, X_{t+j}) \overset{d}{=} (X_{t+h}, X_{t+1+h}, \ldots, X_{t+j+h})\,, \quad \forall h \geq 0 \, , $$
			onde $\overset{d}{=}$ significa igualdade das distribuições conjuntas, isto é
			
			\begin{align*}
				\mathbb{P}[X_t \leq c_1, X_{t+1} \leq c_2, \ldots, X_{t+j} \leq c_j ] = \\ \mathbb{P}[X_{t+h} \leq c_1, X_{t+1+h} \leq c_2, \ldots, X_{t+j+h} \leq c_j ], \quad \forall c_1,c_2\ldots, c_j \, .
			\end{align*}
			
			\item Estacionariedade estrita requer que distribuição de qualquer número finito de períodos do processo seja a mesma ao longo do tempo.
		\end{itemize}
	\end{frame}
	
		\begin{frame}{Série de tempo fracamente estacionária}
			
			\begin{itemize}
				\item Para modelos lineares de séries de tempo, vamos considerar o conceito de {\color{blue}processo (fracamente) estacionário}.
				\item Uma série de tempo $\{X_t: t \in \mathcal{T}\}$ é dita {\color{blue}(fracamente) estacionária} se:
				\begin{halfwideenumerate}
					\item $\mathbb{E}[X_{t}] = \mu$ para todo $t \in \mathcal{T}$.
					\item $\mathbb{V}[X_{t}] = \sigma^2 < \infty$ para todo $t \in \mathcal{T}$.
					\item $\text{cov}(X_t, X_s) = \phi_{|t-s|}$ para todo $t,s \in \mathcal{T}$.
				\end{halfwideenumerate}
				\item Processo é fracamente estacionário se sua média e variância mantêm-se constantes no tempo e covariância entre duas observações depende somente da distância entre as duas observações no tempo.
				\item Estacionariedade fraca impõe um {\color{blue}mínimo} de estabilidade no processo ao longo do tempo para que análise estatística usual possa prosseguir.
				\begin{itemize}  
					\vspace{-1em}
					\item De modo geral, alguma noção de estacionariedade + dependência fraca entre as observações (observações muito distantes no tempo comportam-se ``como'' observações independentes) vai ser requerida das séries de tempo para o funcionamento ``padrão'' de estimadores.
				\end{itemize}
				\item Processo é dito {\color{blue}não estacionário} se não for fracamente estacionário.
			\end{itemize}

	\end{frame}
	

	
	\begin{frame}{Ruído branco}
	\begin{wideitemize}
		\item Um processo $Z_t$, $t \in \mathcal{T}$, é dito um {\color{blue}ruído branco} se:
		\begin{halfwideenumerate}
			\item $\mathbb{E}[Z_t] = 0$ para todo $t$.
			\item $\mathbb{V}[Z_t] = \sigma^2 < \infty$ para todo $t$.
			\item $\text{cov}(Z_t, Z_s) = 0$ se $t \neq s$.
		\end{halfwideenumerate}
		\item Um ruído branco tem média zero, variância constante finita e não apresenta correlação serial.
		\begin{halfwideitemize}
			\item Por construção, é um processo fracamente estacionário.
		\end{halfwideitemize}
	\end{wideitemize}
\end{frame}
\begin{frame}{Ruído branco (gráfico)}
	\begin{figure}
		\includegraphics[scale=0.5]{graficos/rb.pdf}
	\end{figure}
\end{frame}
\begin{frame}{Processo  MA(q)}
	\begin{halfwideitemize}
			\item Um processo $Z_t$, $t \in \mathbb{Z}$, é dito de média movel de ordem $q$, ou tão somente MA(q), se:
			
			$$Z_t = \mu + \epsilon_t + \sum_{i=0}^{q} \psi_i \epsilon_{t-i} \, ,$$
			onde $\{\epsilon_t\}_{t \in \mathbb{Z}}$ é um ruído branco com variância $\sigma^2_\epsilon$.
			\item Vamos verificar que o processo é (fracamente) estacionário. De fato
			\begin{enumerate}
				\item 			$\mathbb{E}[Z_t] = \mu $.
				\item $\mathbb{V}[Z_t] = \sigma^2_\epsilon(1+ \sum_{j=1}^q\psi^2_j)$.
				\item $\operatorname{cov}( Z_{t+j}, Z_t) = \begin{cases}
					\sigma^2_\epsilon (\psi_{j} + \psi_{j+1}\psi_1 + \ldots + \psi_q \psi_{q-j}), & \text{se } 0 < j  \leq q \\
					0,& \text{se } j  > q
				\end{cases}$
			\end{enumerate}
			\item Processo tem memória curta: correlações desaparecem após $q$ períodos.
	\end{halfwideitemize}
\end{frame}

\begin{frame}{Processo MA(2) com $\psi_1=1$ e $\psi_2 = 0.5$}
		\begin{figure}
		\includegraphics[scale=0.8]{graficos/ma2.pdf}
	\end{figure}
\end{frame}
\begin{frame}{Processo  AR(1) estacionário}
	\begin{wideitemize}
		\item Um processo $Z_t$, $t \in \mathbb{Z}$, é dito autorregressivo de ordem um estacionário, ou tão somente AR(1) estacionário, se:
		\begin{equation*}
			Z_t = \alpha + \rho Z_{t-1} + u_t
		\end{equation*} 
		onde $|\rho| < 1$, $\{u_t\}_{t \in \mathbb{Z}}$ é ruído branco com $\mathbb{V}[u_t] = \sigma^2_u$ existem $S \in \mathbb{Z}$, $C \in \mathbb{R}$  tais que $\mathbb{E}[|Z_t|] \leq C$ para todo $t \leq S$.
		
		\item Vamos verificar que as condições acima garantem que o processo seja, de fato, estacionário.
		\item Note que:
		
		\begin{equation*}
			\begin{aligned}			
				Z_t &=  \alpha + \rho(\alpha + \rho Z_{t-2} + u_{t-1}) + u_{t}  \\
				    &= \alpha + \rho \alpha  + \rho^2(\alpha + \rho Z_{t-3} + u_{t-2}) + u_{t} + \rho u_{t-1} \\
				     &`= \ldots \\
				     & = \sum_{j=0}^{\tau - 1} \rho^{j} \alpha +  \rho^{\tau} Z_{t-\tau} +  \sum_{j=0}^{\tau - 1} \rho^{j} u_{t-j}\\
			\end{aligned}
		\end{equation*}
		
		

	\end{wideitemize}
\end{frame}

\begin{frame}{Processo AR(1) estacionário (cont.)}
	\begin{halfwideitemize}
		\item Pelas hipóteses, $\lim_{\tau \to \infty} |\rho|^{\tau} \mathbb{E}[|Z_{t-\tau}|] = 0$. Isso nos garante que $\rho^{\tau} Z_{t-\tau} \to 0$ e podemos escrever
		
		$$Z_t = \sum_{j=0}^{\infty} \rho^{j} \alpha +   \sum_{j=0}^{\infty } \rho^{j} u_{t-j} = \frac{\alpha}{1-\rho} + \sum_{j=0}^\infty \rho^j u_{t-j}$$
		\item AR(1) estacionário se escreve como MA($\infty$).
		\item Usando representação acima, podemos checar que o processo é estacionário. De fato:
			\begin{halfwideenumerate}
			\item $\mathbb{E}[Z_t] = \frac{\alpha}{1-\rho}$
			\item $\mathbb{V}[Z_t] = \frac{\sigma^2_u}{1-\rho^2}$.
			\item $\operatorname{cor}(Z_t, Z_s) = \rho^{|t-s|}$.
		\end{halfwideenumerate}
	\end{halfwideitemize}
\end{frame}

\begin{frame}{AR(1) estacionário com $\rho = 0.7$ (gráfico)}
	\begin{figure}
		\includegraphics[scale=0.5]{graficos/ar1.pdf}
	\end{figure}
\end{frame}

	
	
		\begin{frame}{Processo AR(p) estacionário}
		\begin{halfwideitemize}
				\item Um processo $Z_t$, $t \in \mathbb{Z}$, é dito autorregressivo de ordem $p$ estacionário, ou tão somente AR(p) estacionário, se:
			\begin{equation*}
				Z_t = \alpha + \beta_1 Z_{t-1} + \beta_2 Z_{t-2}+\ldots + \beta_p Z_{t-p}+ u_t
			\end{equation*} 
			onde  $\{u_t\}_{t \in \mathbb{Z}}$ é ruído branco com $\mathbb{V}[u_t] = \sigma^2_u$, existem $S \in \mathbb{Z}$, $C \in \mathbb{R}$  tais que $\mathbb{E}[|Z_t|] \leq C$ para todo $t \leq S$, e {\color{red}os parâmetros $(\beta_1,\beta_2,\ldots, \beta_p)$ são tais que processo resultante é estacionário}.
			\item No AR(p), processo se escreve como uma combinação linear do que aconteceu nos últimos $p$ períodos, mais uma inovação.
		\end{halfwideitemize}
	\end{frame}
	
	
	\begin{frame}{Operador defasagem}
		\begin{itemize}
			\item Para a análise de séries de tempo, é conveniente definir uma função $L$, denominada operador defasagem, que, para uma dada série de tempo $(X_t)_{t \in \mathcal{T}}$, nos devolve a série de tempo que consiste em  $(X_t)_{t \in \mathcal{T}}$ defasado em um período, i.e.
			
			$$L X_t \overset{\text{definição}}{=} L(X_t) = X_{t-1}, \quad \forall t \in \mathcal{T}$$
			\item A notação $L^d$ será usada para denotar a aplicação do operador $L$ $d$ vezes em sequência, i.e.
			
			$$L^d X_t \overset{\text{definição}}{=} \underbrace{L\ldots L}_{\text{d vezes}} X_t = X_{t-d}\, , \quad \forall t \in \mathcal{T}$$
			\item Por fim, definiremos $L^0 = 1$, de modo que:
			
			$$L^0 X_t = 1 X_t = X_t\, \quad \forall t \in \mathcal{T}$$
		\end{itemize}
	\end{frame}
	
	\begin{frame}{Propriedades do operador defasagem}
		\begin{block}{Lema}
			Sejam $(X_t)_{t \in \mathcal{T}}$ e $(Y_t)_{t \in \mathcal{T}}$ duas séries de tempo, e $\alpha \in \mathbb{C}$ um número complexo. Então
			\begin{enumerate}
				\item (Linearidade) $L(X_t+\alpha Y_t) =LX_t + \alpha LY_t$.
				\item (Existência de soma infinita) Se $(X_t)_{t \in \mathcal{T}}$ é estacionário e  $|\alpha|<1$, o processo
				
				$$Z_t= \sum_{j=0}^{\infty} \alpha^j L^j X_{t} = \sum_{j=0}^{\infty} \alpha^j X_{t-j}\, ,$$
				existe e é estacionário.
				\item (Inversa) Se $(X_t)_{t \in \mathcal{T}}$ é estacionário e  $|\alpha|<1$:
				
				$$(1-\alpha L)^{-1}(X_t) = \sum_{j=0}^{\infty} \alpha^j L^j X_t$$
			\end{enumerate}
		\end{block}
	\end{frame}

	\begin{frame}{AR(p) em notação polinomial}
	\begin{wideitemize}
	\item Usando a notação aprendida anteriormente, podemos reescrever o AR(p) como:
	\begin{equation}
		\label{eq_sol}
		\phi(L)Z_t = \alpha + u_t \, , 
	\end{equation}
	onde $\phi(L) = 1 - \beta_1L - \beta_2 L^2 \ldots - \beta_p L^p$, e $\{u\}_{t \in \mathbb{Z}}$ é ruído branco.
	\item A equação \eqref{eq_sol} define uma equação a diferenças  com parte estocástica.
		\item Nesse ambiente, dizemos que um processo $\{Z_t\}_{t \in \mathbb{Z}}$ é uma {\color{blue}solução} a \eqref{eq_sol} se $\{Z_t\}_{t \in \mathbb{Z}}$ satisfaz \eqref{eq_sol} e, para todo $t$, $Z_t$ é uma função tão somente dos $u_\tau$ de períodos anteriores a $t$, i.e. $\tau \leq t$.
		\begin{halfwideitemize}
			\item Nossa definição de solução se restringe a processos em que o que ocorre com $Z_t$ é somente função do que já ocorreu no passado ou que ocorre no presente, mas não do futuro.
			\begin{itemize}
				\item No jargão probabilístico, nosso conceito de solução se restringe a processo ```causais'', onde ``causalidade'' aqui não é no sentido econométrico, e tão somente um jeito de dizer que a solução respeita a ordenação natural do tempo.
			\end{itemize}
		\end{halfwideitemize}
	\end{wideitemize}
	

		
	
	\end{frame}
	\begin{frame}{Caracterizando as soluções}
			\begin{block}{Proposição}
			Existe um processo $\{Z_t\}_{t \in \mathbb{Z}}$ fracamente estacionário que é solução a \eqref{eq_sol}, se, e somente se, as $p$ raízes da equação $\phi(x) = 0$ se encontram \textbf{fora} do círculo unitário, isto é:
			$$\phi(x) = 0 \implies |x| > 1 \, .$$
			
			Neste caso, o processo fracamente estacionário que satisfaz \eqref{eq_sol} é único, e pode ser escrito como:
			
			$$Z_t = \phi^{-1}(L)(\alpha + u_t) =  \tau + \sum_{j=0}^\infty \omega_j u_{t-j}$$
		\end{block}
	\end{frame}
	\begin{frame}{Estacionariedade do AR(p)}
\begin{itemize}
	\item A proposição anterior nos provê uma caracterização para a existência de um $\{Z_t\}_t$ estacionário que satisfaz \eqref{eq_sol}, em termos das {\color{blue}raízes do polinômio característico} $\phi(x)$.
	\begin{halfwideitemize}
		\item Note que a proposição fala de \textbf{existência} de {\color{red}uma} solução. Por quê?
		\item Isso se deve ao fato de que também podem existir processos $\{Z_t\}_{t \in \mathbb{Z}}$ não estacionários que satisfazem \eqref{eq_sol}, mesmo quando as raízes estão todas fora do círculo.
		\begin{halfwideitemize}
			\item Mas o teorema nos diz que, se ao menos uma das raízes está \textbf{dentro} do círculo, com certeza não há nenhuma solução estacionária.
		\end{halfwideitemize}
		\item A restrição que fazíamos, na definição de AR(p) estacionário, de que o passado não explodia, justamente descartava as soluções não estacionárias, garantindo que selecionássemos a solução estacionária.
	\end{halfwideitemize}
			\item No curso e na vida, vamos seguir como tradicionalmente feito na literatura econométrica e implicitamente \textbf{sempre} descartar as soluções não estacionárias (explosivas) que existem mesmo quando todas as raízes estão fora do círculo.
			\begin{halfwideitemize}
				\item {\color{green}Dessa forma, diremos que um AR(p) é fracamente estacionário se, e somente se, \textbf{todas} as raízes de $\phi(x)$ estão fora do círculo.}
			\end{halfwideitemize}
\end{itemize}
\end{frame}
\begin{frame}{Encontrando os coeficientes da representação MA($\infty$)}
	\begin{itemize}
		\item As propriedades do operador defasagem podem ser utilizadas para encontrar a representação MA($\infty$) de um AR($p$) estacionário.
		\item De fato, considere um AR($2$) estacionário:
		$$(1-\beta_1 L - \beta_2 L^2)y_t = \alpha + u_t$$
		\item Da fatoração de polinômios,  podemos escrever:
		$$(1-\beta_1 x - \beta_2 x^2) = \left(\frac{1}{\lambda_1}x-1\right)\left(\frac{1}{\lambda_2}x-1\right)\, ,$$
		onde $\lambda_1$ e $\lambda_2$ são as raízes de $(1- x - \beta_2 x^2) = 0$.
		\item Portanto:
		$$(1-\beta_1 L - \beta_2 L^2)y_t =   \left(1- \frac{1}{\lambda_1}L\right) \left(1-\frac{1}{\lambda_2}L\right)y_t = \alpha + u_t$$
	\end{itemize}
\end{frame}

\begin{frame}{Encontrando os coeficientes da representação MA($\infty$)}
	\begin{halfwideitemize}
		\item Mas então 
		\begin{equation}
			\begin{aligned}
				y_t = (1-\beta_1 L - \beta_2 L^2)^{-1}(\alpha + u_t) = \\ \left(1-\frac{1}{\lambda_2}L\right)^{-1}\left(1- \frac{1}{\lambda_1}L\right)^{-1}(\alpha+u_t) = \\
				 \left(\sum_{i=0}^\infty \frac{1}{\lambda_2^i} L^i\right) \left(\sum_{j=0}^\infty \frac{1}{\lambda_1^j}L^j\right)(\alpha + u_t) =\\
				 \frac{1}{(1-\lambda_1^{-1})(1-\lambda_2^{-1})}\alpha + \sum_{k=0}^\infty \omega_k u_{t-k} \end{aligned}
		\end{equation}
		onde $\omega_k$ é a soma de termos $\frac{1}{\lambda^i_1 \lambda^j_2}$ tais que $i+j=k$, i.e. $\omega_k = \sum_{i=0}^k \frac{1}{\lambda^i_2 \lambda^{k-i}_2}$.
	\end{halfwideitemize}
\end{frame}

\begin{frame}{ARMA(p,q)}
	
	\begin{halfwideitemize}
		\item Um processo $\{Y_t\}_{t \in \mathbb{Z}}$ é dito ARMA(p,q) se:
		
		$$Y_t = \alpha + \sum_{j=1}^p \gamma_j Y_{t-j} + \epsilon_t + \sum_{l=1}^q \pi_l \epsilon_{t-l} \, ,$$
		onde $\{\epsilon_t\}_{t \in \mathbb{Z}}$ é ruído branco.
		
		\item Processo ARMA(p,q) tem notação polinomial:
		
		$$\Gamma(L)Y_t = \alpha + \Pi(L)\epsilon_t \, ,$$
		onde $\Gamma(L) = (1-\gamma_1L -\gamma_2 L^2 \ldots -\gamma_p L^p)$ e $\Pi(L) = (1+\pi_1L +\pi_2 L^2 \ldots +\pi_q L^q)$.
			\item Um ARMA($p$,$q$) é dito em {\color{blue}forma simplificada} se $\Gamma$ e $\Pi$ não possuem raízes em comum, i.e. $\Gamma(x) =0 \implies \Pi(x) \neq 0$ e $\Pi(x) = 0 \implies \Gamma(x) \neq 0$.
		
		\begin{itemize}
			\item Sempre é possível colocar um ARMA em forma simplificada, fatorando os dois polinômios em termos das raízes comuns e cortando-os dos dois lados.
		\end{itemize}
	
	\end{halfwideitemize}
\end{frame}

\begin{frame}{Estacionariedade do ARMA(p,q)}
	\begin{itemize}
		\item A estacionariedade do ARMA(p,q) depende, fundamentalmente, do comportamento da parte AR.
	\end{itemize}
					\begin{block}{Proposição}
		Considere um processo ARMA(p,q). Se, as $p$ raízes da equação característica $\Gamma(x) = 0$ estão todas fora do círculo unitário, então o ARMA($p$,$q$) é estacionário. Por outro lado, se o ARMA($p$,$q$) está em forma simplificada e uma das raízes de $\Gamma(x)$ está dentro do círculo (i.e. existe $\Gamma(x^*)=0$ com $|x^*| \leq 1$), o ARMA(p,q) não é estacionário.
	\end{block}
\end{frame}
\begin{frame}{Processo ARMA(p,q) invertível}
	\begin{halfwideitemize}
		\item 	Um ARMA(p,q) estacionário é dito {\color{blue}invertível} se admite representação AR($\infty$), i.e. se pode ser escrito como:
		$$Y_t = \omega +\sum_{j=1}^\infty \kappa_j Y_{t-j} + \epsilon_t\, .$$
		
		\item Invertibilidade depende do comportamento da parte MA.
		
				\begin{block}{Proposição}
			Considere um processo ARMA(p,q) estacionário. Se, as $q$ raízes da equação característica $\Pi(x) = 0$ estão todas fora do círculo unitário, então o ARMA($p$,$q$) é invertível. Por outro lado, se o ARMA($p$,$q$) está em forma simplificada e uma das raízes de $\Pi(x)$ está dentro do círculo  (i.e. existe $\Pi(x^*)=0$ com $|x^*| \leq 1$), o ARMA(p,q) não é invertível.
		\end{block}
		\item Invertibilidade será importante para distinguirmos entre processos ARMA.
	\end{halfwideitemize}

\end{frame}

\begin{frame}{Método para verificar estacionariedade e invertibilidade do ARMA}
	\begin{halfwideitemize}
		\item Para verificar a estacionariedade do ARMA($p$,$q$).
		\begin{enumerate}
			\item Calcular as $p$ raízes de $\Gamma(x) = 0$. Se todas estão fora do círculo, processo é estacionário.
			\item Se há raízes dentro do círculo, calculá-las (tratar raízes em multiplicidade como distintas). Se todas as raízes dentro do círculo de $\Gamma$ aparecem como raízes de $\Pi(x) = 0$ (as raízes em multiplicidade  precisam aparecer pelo menos o mesmo número de vezes repetidas em $\Pi$), o  processo ainda é estacionário. Se não for o caso, o processo é não estacionário.
		\end{enumerate}
		
			\item Para verificar a invertibilidade do ARMA($p$,$q$) \textbf{estacionário}.
		\begin{enumerate}
			\item Calcular as $q$ raízes de $\Pi(x) = 0$. Se todas estão fora do círculo, processo é invertível.
			\item Se há raízes dentro do círculo, calculá-las (tratar raízes em multiplicidade como distintas). Se todas as raízes dentro do círculo de $\Pi$ aparecem como raízes de $\Gamma(x) = 0$ (as raízes em multiplicidade  precisam aparecer pelo menos o mesmo número de vezes repetidas em $\Gamma$), o  processo ainda é invertível. Se não for o caso, o processo não é invertível.
		\end{enumerate}
	\end{halfwideitemize}
\end{frame}

\begin{frame}{ARMA(1,2) (gráfico)}
	\centering
	\includegraphics[scale=0.7]{graficos/arma12.pdf}
\end{frame}
\begin{frame}{Processo não estacionário: tendência determinística}
	\begin{halfwideitemize}
		\item Considere, agora, o processo:
		\begin{equation}
			\label{eq_trend}
			Z_t = \alpha + \beta \cdot t + u_t
		\end{equation}
		onde $\beta \neq 0$ e $\{u_t\}_t$ é ruído branco. Note que esse processo é {\color{blue}não estacionário}, visto que:
		\begin{equation*}
			\mathbb{E}[Z_t] = \alpha + \beta \cdot t
		\end{equation*}
		varia no tempo.
		\item Processo é estacionário {\color{blue} em torno de uma tendência}.
		\item Dizemos que processos que incluem componentes determinísticos da forma $f(t)$, onde $f$ é uma função do tempo, apresentam {\color{blue}tendência determinística}. 
	\end{halfwideitemize}
\end{frame}
\begin{frame}{Exemplo de processo com tendência determinística (gráfico)}
	\begin{figure}
		\caption{$Z_t = 0.05 \cdot t + u_t$, $u_t \sim N(0,1)$}
		\includegraphics[scale=0.4]{graficos/deterministica.pdf}
	\end{figure}
\end{frame}

\begin{frame}{Processo não estacionário: tendência estocástica}
	\begin{halfwideitemize}
		\item Considere agora um {\color{blue}passeio aleatório simples}, definido como:
		\begin{equation}
			\label{eq_rw}
			Z_t = Z_{t-1} + u_t, \quad t > 0
		\end{equation}
		onde $\{u_t\}_{t \in \mathbb{N}}$ é ruído branco, e $Z_0 = 0$. 
		\item Nesse caso, é possível verificar que:
		\begin{equation}
			\label{eq_stoch_trend}
			Z_t = \sum_{s=1}^t u_s, \quad t > 0
		\end{equation}
		e vemos que o processo é não estacionário, visto que:
		\begin{equation*}
			\mathbb{V}[Z_t] = t \cdot \sigma^2_u
		\end{equation*}
		\item De \eqref{eq_stoch_trend}, notamos que o processo apresenta {\color{blue}tendência estocástica}: choques têm efeito permanente no nível da série.
	\end{halfwideitemize}
	
\end{frame}

\begin{frame}{Exemplo de processo com tendência estocástica (gráfico)}
	\begin{figure}
		\caption{Passeio aleatório simples}
		\includegraphics[scale=0.4]{graficos/rw.pdf}
	\end{figure}
\end{frame}
\begin{frame}{Processo não estacionário: quebra estrutural}
	\begin{halfwideitemize}
		\item Um terceiro tipo de processo não estacionário é dado por:
		
		\begin{equation}
			\label{break_mean}
				Y_t = \begin{cases}
					\mu_0 + u_t \, ,& \text{se } t \leq T \, \\
					\mu_1 + u_t \, , & \text{se } t > T \, 
				\end{cases}
		\end{equation}
		onde $\{u_t\}_{t \in \mathbb{N}}$ é ruído branco e $\mu_0 \neq \mu_1$.
		\item Processo apresenta quebra de {\color{blue}nível}: média é $\mu_0$ até $T$, e $\mu_1$ para a frente.
		
		\item Outro tipo de processo com {\color{blue}quebra de estrutura} é dado por:
		
				\begin{equation}
			Y_t = \begin{cases}
				 u_t \, ,& \text{se } t \leq T \, \\
				\sigma u_t \, , & \text{se } t > T \, 
			\end{cases}
		\end{equation}
		para $\sigma \neq 1$. Processo apresenta {\color{blue}quebra de escala ou na variância}.
	\end{halfwideitemize}
\end{frame}

\begin{frame}{Processo não estacionário: quebra estrutural (gráfico)}
	\begin{figure}
	\begin{subfigure}{0.5\textwidth}
		\centering
		\includegraphics[scale=0.4]{graficos/break_mean.pdf}
		\caption{Quebra de nível}
		
	\end{subfigure}\begin{subfigure}{0.5\textwidth}
			\centering
					\includegraphics[scale=0.4]{graficos/break_sd.pdf}
		\caption{Quebra de escala}
	\end{subfigure}
	\end{figure}
\end{frame}
\begin{frame}{Removendo não estacionariedades}
	\begin{halfwideitemize}
		\item Cada tipo de estacionariedade enseja um tratamento particular.
		\item Podemos remover a tendência determinística do processo \eqref{eq_trend} ajustando um modelo linear de $Z_t$ em $t$ e extraindo os resíduos.
		\begin{halfwideitemize}
			\item Também é possível trabalhar com a série em {\color{blue}primeira diferenças}, isto é, trabalhar com a série $Y_t = Z_{t} - Z_{t-1}$ embora isso não seja a maneira mais eficiente de fazê-lo (e não funciona para tendências não lineares).
		\end{halfwideitemize}
		\item Por outro lado, para remover a tendência estocástica em \eqref{eq_rw}, devemos trabalhar com a {\color{blue}série diferenciada} $\Delta Z_t = Z_{t} - Z_{t-1}$.
		\begin{halfwideitemize}
			\item Observe que, de \eqref{eq_rw}, $\Delta Z_t = Z_t-Z_{t-1}$ é um processo estacionário.
		\end{halfwideitemize} 
		\item Por fim, para processos com quebra estrutural, o ideal é analisar os processos em janelas separadas, dentro das quais há estacionariedade.
		\begin{itemize}
			\vspace{-1em}
			\item O problema, neste caso, é identificar o ponto de quebra $T$.
		\end{itemize}
	\end{halfwideitemize}
\end{frame}

\begin{frame}{Os diferentes tipos de não estacionariedade}
	\begin{halfwideitemize}
		\item Processos com tendência determínistica, que se tornam estacionários após a subtração de uma $f(t)$, são conhecidos como estacionários em torno de tendência ({\color{blue}\textit{trend-stationary}}). 
					\item Processos com {\color{blue}tendência estocástica, que requerem diferenciação para se tornarem estacionários}, são conhecidos como {\color{blue}I(1) ou com uma raiz unitária}.
		\item Processos {\color{blue}estacionários} são conhecidos como {\color{blue}I(0)}.
		\item Nas próximas aulas, desenvolveremos métodos estatísticos para distinguir entre os três processos.
		\begin{itemize}
			\item Não vamos focar na detecção de quebra estrutural, embora seja importante saber que esta é uma área ativa da Econometria.
			\item Mas, se der tempo, veremos como quebras ``exógenas'' de variância podem ser usadas na identificação de efeitos causais.
		\end{itemize} 
	\end{halfwideitemize}

\end{frame}


	%\begin{frame}[allowframebreaks]{Bibliografia}
	%\printbibliography
	%\end{frame}
\end{document}